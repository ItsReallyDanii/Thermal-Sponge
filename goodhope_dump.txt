========== FILE: .gitignore ==========

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[codz]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py.cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock
#poetry.toml

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.
#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control
#pdm.lock
#pdm.toml
.pdm-python
.pdm-build/

# pixi
#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.
#pixi.lock
#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one
#   in the .venv directory. It is recommended not to include this directory in version control.
.pixi

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.envrc
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Abstra
# Abstra is an AI-powered process automation framework.
# Ignore directories containing user credentials, local state, and settings.
# Learn more at https://abstra.io/docs
.abstra/

# Visual Studio Code
#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore 
#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore
#  and can be added to the global gitignore or merged into this file. However, if you prefer, 
#  you could uncomment the following to ignore the entire vscode folder
# .vscode/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

# Cursor
#  Cursor is an AI-powered code editor. `.cursorignore` specifies files/directories to
#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data
#  refer to https://docs.cursor.com/context/ignore-files
.cursorignore
.cursorindexingignore

# Marimo
marimo/_static/
marimo/_lsp/
__marimo__/


========== FILE: LICENSE ==========

MIT License

Copyright (c) 2025 ItsReallyDanii

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


========== FILE: README.md ==========

# Inverse Design of Functionally Graded Porous Media
### *A Physics-Informed Generative Approach to Biological & Thermal Transport*

![Status](https://img.shields.io/badge/Status-Research_Artifact-blue) ![Domain](https://img.shields.io/badge/Domain-SciML-green) ![License](https://img.shields.io/badge/License-MIT-lightgrey)

**Key Finding:** Validated a generative design engine that creates microstructures with **3x hydraulic stiffness** compared to biological xylem and **300% better flow efficiency** than chaotic thermal foams.

---

## üìÑ Abstract

Transport microstructures‚Äîwhether in biological xylem or electronic cooling plates‚Äîare often limited by a trade-off between **efficiency** (flow rate/heat flux) and **material cost** (density/pressure drop). Traditional topology optimization is computationally expensive, while bio-mimicry often copies evolutionary constraints (like growth) that are irrelevant to engineering.

This project introduces a **Physics-Informed Generative Design Framework**. By training a surrogate-assisted autoencoder on biological data and fine-tuning it via differentiable physics solvers, we created a "Material Compiler" capable of inverse-designing microstructures for specific multi-physics targets.

We demonstrate the framework's generalizability across two distinct domains:
1.  **Biological Hydraulics:** Identifying a "minimal viable xylem" that matches biological flow rates with only **15% porosity** (vs. 43% in nature).
2.  **Thermal Management:** Generating "organic fin" topologies that achieve the cooling performance of chaotic foams while maintaining the low hydraulic resistance of straight fins.

---

## üìä Key Results

### 1. The Hydraulic Efficiency Gap (Xylem Audit)
We mapped the trade-off between **Flow Rate** (Simulated via Darcy solver) and **Stiffness Potential** (Heuristic $E \propto \rho^2$).

* **Finding:** The AI identified a Pareto front of designs that are **~3x stiffer** than biological xylem for the equivalent hydraulic conductivity.
* **Implication:** This suggests ~65% of the void space in real xylem is hydraulically redundant in steady-state conditions, likely serving structural safety factors (cavitation/wind stress) rather than transport roles.

![Trade-off Plot](results/flow_stiffness_tradeoff.png)
*(Figure 1: AI-optimized microstructures [circled] vs. biological baselines.)*

### 2. Thermal Generalization (The "Cooling Coral")
We retrained the physics engine to solve the **Steady-State Heat Diffusion Equation** ($\nabla \cdot (k \nabla T) = 0$) to design heat sinks for high-performance electronics.

* **Benchmark:** We compared AI designs against standard Engineering Baselines (Straight Fins, Cross-Hatch Grids) and Random Noise (Chaotic Foam).
* **The Efficiency Win:** While Random Noise achieved the highest raw cooling flux, it suffered from massive hydraulic resistance. The AI design matched the **Low Resistance (~1.0)** of straight fins while delivering **significantly higher Heat Flux**.

![Multi-Physics Frontier](results/baselines/multiphysics_frontier.png)
*(Figure 2: The Multi-Physics Pareto Front. AI designs (Red) occupy the optimal "High Flux / Low Resistance" quadrant, beating standard baselines.)*

### 3. Design Control (The "Manifold")
To prove controllability, we performed an inverse design sweep across a $5 \times 5$ target matrix, requesting specific combinations of **Heat Flux** and **Material Density**.

* **Result:** The model successfully interpolated the latent space, producing a smooth morphological transition from "Wispy Webs" (Low Flux/Density) to "Dense Corals" (High Flux/Density).

![Design Manifold](results/thermal_design/design_manifold.png)
*(Figure 3: 5x5 Inverse Design Sweep demonstrating control over physical properties.)*

---

## üõ† Manufacturability & 3D Assets

Unlike many generative models that produce "pixel dust," this framework enforces structural connectivity.

* **Connectivity Audit:** 100% of generated samples achieved a connectivity score > 0.90 (Largest Connected Component).
* **Functionally Graded Materials (FGM):** We successfully generated a continuous beam transitioning from **Dense ($E_{high}$)** to **Porous ($E_{low}$)**.

### üìÇ Included Artifacts
* **`results/gradient_beam/gradient_beam_3d.stl`**: A manufacturing-ready 3D mesh of the gradient structure, generated via Marching Cubes (Voxel Scale = 1.0mm).
* **`results/thermal_metrics.csv`**: Full dataset of simulated thermal performance for 128 generated structures.
* **`results/baselines/baseline_metrics.csv`**: Performance data for standard engineering geometries.

---

## üîÆ Future Directions
This work establishes a "Computational Testbed" for inverse material design. Immediate expansions include:
Acoustic Metamaterials: Retraining the surrogate on the Helmholtz equation to design noise-damping tiles with high air permeability.
Closed-Loop Robotics: Connecting the generator to a 3D printer and flow-test rig to allow the AI to learn from physical reality rather than simulation.
Mechanical Simulation: Replacing the stiffness heuristic (E‚àùœÅ2) with a differentiable FEM solver to optimize for specific load-bearing paths.

üìö Citation
Daniel Sleiman. (2025). Inverse Design of Functionally Graded Porous Media via Physics-Informed Generative Models. GitHub Repository.


## üß† System Architecture

The framework consists of three coupled modules:

```mermaid
graph TD
    A[Geometry Generator] -->|Latent Code z| B(Decoder)
    B -->|Microstructure| C{Physics Surrogate}
    C -->|Predict Flow/Heat| D[Optimizer]
    D -->|Gradient Update| A
    B -->|Validation| E[FEM/FDM Solver]

The Eye (Autoencoder): Learns the manifold of valid porous structures.
The Brain (Surrogate): Differentiable CNN that predicts physics (R2>0.95).
The Hand (Optimizer): Performs gradient descent in latent space to hit target metrics.




========== FILE: analyze_flow_metrics.py ==========

import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import ttest_ind, ks_2samp

# -----------------------------
# üß† CONFIG
# -----------------------------
CSV_PATH = "results/flow_metrics/flow_metrics.csv"
OUTPUT_DIR = "results/metric_distributions"
REPORT_PATH = "results/physics_validation_report.csv"

os.makedirs(OUTPUT_DIR, exist_ok=True)

# -----------------------------
# üì• LOAD DATA
# -----------------------------
print(f"üìÇ Loading: {CSV_PATH}")
df = pd.read_csv(CSV_PATH)

# Split real vs synthetic
real = df[df["Type"].str.lower() == "real"]
synthetic = df[df["Type"].str.lower() == "synthetic"]

# Columns to analyze
metrics = ["Mean_K", "Mean_dP/dy", "FlowRate", "Porosity", "Anisotropy"]

# -----------------------------
# üìä ANALYSIS
# -----------------------------
report = {}

for metric in metrics:
    if metric not in df.columns:
        print(f"‚ö†Ô∏è Skipping {metric} ‚Äî not found in CSV.")
        continue

    # Replace slash in filenames
    safe_metric = metric.replace("/", "_")

    # Plot distributions
    plt.figure(figsize=(6, 4))
    plt.hist(real[metric], bins=10, alpha=0.6, label="Real", density=True)
    plt.hist(synthetic[metric], bins=10, alpha=0.6, label="Synthetic", density=True)
    plt.title(f"{metric}: Real vs Synthetic")
    plt.xlabel(metric)
    plt.ylabel("Density")
    plt.legend()
    plt.tight_layout()

    save_path = os.path.join(OUTPUT_DIR, f"{safe_metric}_distribution.png")
    plt.savefig(save_path, dpi=120)
    plt.close()
    print(f"‚úÖ Saved: {save_path}")

    # Statistical tests
    t_stat, t_p = ttest_ind(real[metric], synthetic[metric], equal_var=False, nan_policy="omit")
    ks_stat, ks_p = ks_2samp(real[metric], synthetic[metric])

    report[metric] = {
        "real_mean": np.nanmean(real[metric]),
        "synthetic_mean": np.nanmean(synthetic[metric]),
        "t_p_value": round(t_p, 5),
        "ks_p_value": round(ks_p, 5),
    }

# -----------------------------
# üíæ SAVE REPORT
# -----------------------------
report_df = pd.DataFrame(report).T
os.makedirs(os.path.dirname(REPORT_PATH), exist_ok=True)
report_df.to_csv(REPORT_PATH)
print(f"\nüßæ Physics validation report saved ‚Üí {REPORT_PATH}\n")

# -----------------------------
# üßÆ AUTO SUMMARY
# -----------------------------
similar_t = (report_df["t_p_value"] > 0.05).sum()
similar_ks = (report_df["ks_p_value"] > 0.05).sum()
total = len(report_df)

summary = f"""
üåø Flow Physics Validation Summary
-----------------------------------
‚úÖ Metrics analyzed: {total}
‚úÖ Metrics statistically similar (T-test): {similar_t}/{total}
‚úÖ Metrics distribution-similar (KS-test): {similar_ks}/{total}

Interpretation:
If most p-values > 0.05, your generated xylem behaves
statistically like real xylem under flow physics.
"""

print(summary)
print("\nüìä Detailed Metric Comparison:\n")
print(report_df)

========== FILE: default.jupyterlab-workspace ==========

{"data":{"file-browser-filebrowser:columns":{"sizes":{"name":129.2911834716797,"file_size":null,"is_selected":18,"last_modified":83.09706115722656}},"layout-restorer:data":{"main":{"dock":{"type":"tab-area","currentIndex":1,"widgets":["editor:synthetic_tree_physics/src/build_surrogate_dataset.py","terminal:2","editor:synthetic_tree_physics/src/generate_structures.py","editor:synthetic_tree_physics/src/train_physics_informed.py","editor:synthetic_tree_physics/src/train_surrogate.py"]},"current":"terminal:2"},"down":{"size":0,"widgets":[]},"left":{"collapsed":false,"visible":true,"current":"filebrowser","widgets":["filebrowser","running-sessions","git-sessions","@jupyterlab/toc:plugin","extensionmanager.main-view"],"widgetStates":{"jp-running-sessions":{"sizes":[0.16666666666666666,0.16666666666666666,0.16666666666666666,0.16666666666666666,0.16666666666666666,0.16666666666666666],"expansionStates":[false,false,false,false,false,false]},"jp-collaboration-panel":{"sizes":[0,1],"expansionStates":[false,false]},"extensionmanager.main-view":{"sizes":[0,0.2882511010366503,0.7117488989633497],"expansionStates":[false,false,false]}}},"right":{"collapsed":true,"visible":true,"widgets":["jp-property-inspector","debugger-sidebar"],"widgetStates":{"jp-debugger-sidebar":{"sizes":[0.2,0.2,0.2,0.2,0.2],"expansionStates":[false,false,false,false,false]}}},"relativeSizes":[0.1697872628726287,0.8302127371273713,0],"top":{"simpleVisibility":true}},"docmanager:recents":{"opened":[{"path":"synthetic_tree_physics/src","contentType":"directory","root":"/home/jovyan"},{"path":"synthetic_tree_physics/src/generate_structures.py","contentType":"file","factory":"Editor","root":"/home/jovyan"},{"path":"synthetic_tree_physics/src/train_physics_informed.py","contentType":"file","factory":"Editor","root":"/home/jovyan"},{"path":"synthetic_tree_physics/src/untitled.py","contentType":"file","factory":"Editor","root":"/home/jovyan"},{"path":"synthetic_tree_physics/src/build_surrogate_dataset.py","contentType":"file","factory":"Editor","root":"/home/jovyan"},{"path":"lammps","contentType":"directory","root":"/home/jovyan"},{"path":"lammps/Untitled.ipynb","contentType":"notebook","factory":"Notebook","root":"/home/jovyan"},{"path":"chat/f47fef92-a087-43ea-98d4-20569ca9774c","contentType":"directory","root":"/home/jovyan"},{"path":"chat/f47fef92-a087-43ea-98d4-20569ca9774c/5d6465a5-fd1c-4dfb-b780-cdba44725328_code.ipynb","contentType":"notebook","factory":"Notebook","root":"/home/jovyan"},{"path":"lammps/CLAUDE.md","contentType":"file","factory":"Editor","root":"/home/jovyan"}],"closed":[{"path":"synthetic_tree_physics/src/train_physics_informed.py","contentType":"file","factory":"Editor","root":"/home/jovyan"},{"path":"synthetic_tree_physics/src/generate_structures.py","contentType":"file","factory":"Editor","root":"/home/jovyan"},{"path":"lammps/Untitled.ipynb","contentType":"notebook","factory":"Notebook","root":"/home/jovyan"},{"path":"lammps/CLAUDE.md","contentType":"file","factory":"Editor","root":"/home/jovyan"},{"path":"lammps/app.json","contentType":"file","factory":"JSON","root":"/home/jovyan"},{"path":"chat/f47fef92-a087-43ea-98d4-20569ca9774c/5d6465a5-fd1c-4dfb-b780-cdba44725328_code.ipynb","contentType":"notebook","factory":"Notebook","root":"/home/jovyan"},{"path":"Untitled.ipynb","contentType":"notebook","factory":"Notebook","root":"/home/jovyan"}]},"file-browser-filebrowser:cwd":{"path":"synthetic_tree_physics/results"},"terminal:2":{"data":{"name":"2"}},"editor:synthetic_tree_physics/src/build_surrogate_dataset.py":{"data":{"path":"synthetic_tree_physics/src/build_surrogate_dataset.py","factory":"Editor"}},"editor:synthetic_tree_physics/src/train_surrogate.py":{"data":{"path":"synthetic_tree_physics/src/train_surrogate.py","factory":"Editor"}},"editor:synthetic_tree_physics/src/train_physics_informed.py":{"data":{"path":"synthetic_tree_physics/src/train_physics_informed.py","factory":"Editor"}},"editor:synthetic_tree_physics/src/generate_structures.py":{"data":{"path":"synthetic_tree_physics/src/generate_structures.py","factory":"Editor"}}},"metadata":{"id":"default","last_modified":"2025-12-02T00:01:34+00:00","created":"2025-12-02T00:01:42+00:00"}}

========== FILE: dump_repo.py ==========

import os
import sys

# --- Configuration ---
# Folders to skip (e.g., large data, results, environment files)
SKIP_DIRS = {".git", "node_modules", ".venv", "__pycache__", "data", "results"}

def dump_repository(root_dir, output_file="goodhope_dump.txt"):
    """Walks the directory and compiles all file content into a single output file."""
    
    # 1. Gather all file paths
    files_to_dump = []
    for root, dirs, files in os.walk(root_dir):
        # Modify dirs in-place to prune directories we don't want to visit next
        dirs[:] = [d for d in dirs if d not in SKIP_DIRS]
        
        for file in files:
            full_path = os.path.join(root, file)
            files_to_dump.append(full_path)

    # Sort files for consistent output ordering
    files_to_dump.sort()

    # 2. Compile content
    out = []
    root_abs = os.path.abspath(root_dir)

    for file_path in files_to_dump:
        # Get the relative path for the label
        rel_path = os.path.relpath(file_path, root_dir)
        
        # Skip output files that might be in the root directory
        if rel_path == output_file:
            continue

        text = ""
        try:
            # Attempt to read as UTF-8 (standard for code files)
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
        except UnicodeDecodeError:
            # Fallback for binary or non-UTF8 files (will include garbage characters, but dumps content)
            print(f"Warning: Non-UTF8 content in {rel_path}. Reading as bytes.")
            try:
                with open(file_path, 'rb') as f:
                    text = f.read().decode('latin-1') # Use a simple, lossy decode for the dump
            except Exception as e:
                text = f"--- ERROR READING FILE: {e} ---"

        # Format the entry with clear labels
        out.append(f"========== FILE: {rel_path} ==========\n\n{text}\n\n")

    # 3. Write to output file
    try:
        with open(output_file, 'w', encoding='utf-8') as outfile:
            outfile.write("".join(out))
        print(f"Successfully compiled all files into {output_file}!")
    except Exception as e:
        print(f"ERROR WRITING OUTPUT FILE: {e}")

# --- Execution ---
if __name__ == "__main__":
    # Allows passing arguments from the command line interface
    # e.g., python dump_repo.py . my_code_dump.txt
    
    # Default to current directory and default output name
    target_dir = sys.argv[1] if len(sys.argv) > 1 else "."
    output_name = sys.argv[2] if len(sys.argv) > 2 else "goodhope_dump.txt"

    dump_repository(target_dir, output_name)

========== FILE: requirements.txt ==========

torch
torchvision
matplotlib
numpy
Pillow


========== FILE: src/__init__.py ==========



========== FILE: src/analyze_connectivity.py ==========

import os
import pandas as pd
import numpy as np
import torch
from PIL import Image
from skimage import measure

# Configuration
DATA_DIR = "data/generated_microtubes/"
OUTPUT_CSV = "results/connectivity_metrics.csv"
THRESHOLD = 0.80  # Must match your flow solver!

def calculate_connectivity(img_array, threshold):
    # 1. Binarize: Solid is where pixel <= threshold (assuming white=void, black=solid)
    # If your images are (0=black=solid, 1=white=void), then Solid is < Threshold.
    # Adjust logic if your images are inverted. Assuming standard Xylem: Dark = Wall.
    
    # Normalize to 0-1 if 0-255
    if img_array.max() > 1.0:
        img_array = img_array / 255.0
        
    # Solid Mask (The Material)
    # If pixels are Void-probability (1.0 = hole), then Solid is < 0.8
    solid_mask = img_array < threshold
    
    if not np.any(solid_mask):
        return 0.0, 0.0 # Empty image
        
    # 2. Label Connected Components
    # connectivity=2 means including diagonals
    labels = measure.label(solid_mask, connectivity=2)
    
    if labels.max() == 0:
        return 0.0, 0.0
        
    # 3. Find Largest Component
    regions = measure.regionprops(labels)
    # Sort by area (number of pixels)
    regions.sort(key=lambda x: x.area, reverse=True)
    
    largest_area = regions[0].area
    total_solid_area = np.sum(solid_mask)
    
    # 4. Connectivity Score: (Largest Connected Mass) / (Total Mass)
    # 1.0 = Perfect Monolith. 0.1 = Dust Cloud.
    connectivity_score = largest_area / total_solid_area
    
    return connectivity_score, total_solid_area

def main():
    if not os.path.exists(DATA_DIR):
        print(f"Directory not found: {DATA_DIR}")
        return

    records = []
    files = sorted([f for f in os.listdir(DATA_DIR) if f.endswith('.png')])
    
    print(f"üîç Analyzing connectivity for {len(files)} generated structures...")
    print(f"   Threshold: {THRESHOLD} (Pixels < {THRESHOLD} are SOLID)")

    for f in files:
        path = os.path.join(DATA_DIR, f)
        try:
            img = Image.open(path).convert('L')
            img_arr = np.array(img)
            
            score, mass = calculate_connectivity(img_arr, THRESHOLD)
            
            records.append({
                "filename": f,
                "connectivity_score": score,
                "solid_pixels": mass
            })
        except Exception as e:
            print(f"Error processing {f}: {e}")

    # Save Results
    df = pd.DataFrame(records)
    df.to_csv(OUTPUT_CSV, index=False)
    
    # Summary
    mean_score = df['connectivity_score'].mean()
    print(f"\n‚úÖ Connectivity analysis complete.")
    print(f"   Average Connectivity Score: {mean_score:.4f}")
    print(f"   Results saved to: {OUTPUT_CSV}")
    
    # Check for "Dust"
    dusty_samples = df[df['connectivity_score'] < 0.90]
    if len(dusty_samples) > 0:
        print(f"‚ö†Ô∏è  WARNING: {len(dusty_samples)} images have < 90% connectivity (Dust risk).")
        print(dusty_samples.head())
    else:
        print("üéâ SUCCESS: All samples are > 90% connected. No dust clouds found.")

if __name__ == "__main__":
    main()

========== FILE: src/analyze_flow_metrics.py ==========

import os
import pandas as pd
import numpy as np
from scipy.stats import ttest_ind, ks_2samp

def analyze_flow_metrics(csv_path="results/flow_metrics/flow_metrics.csv"):
    # ------------------------------------------------------------------
    # üìÇ Load and sanity check
    # ------------------------------------------------------------------
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"üö´ Flow metrics file not found: {csv_path}")

    df = pd.read_csv(csv_path)
    df.columns = [c.lower() for c in df.columns]  # make case-insensitive

    required_cols = {"type", "mean_k", "mean_dp/dy", "flowrate", "porosity", "anisotropy"}
    if not required_cols.issubset(set(df.columns)):
        raise KeyError(f"Missing columns in CSV. Expected: {required_cols}, found: {set(df.columns)}")

    # ------------------------------------------------------------------
    # üß© Split real vs synthetic
    # ------------------------------------------------------------------
    real = df[df["type"].str.lower() == "real"]
    synth = df[df["type"].str.lower() == "synthetic"]

    if len(real) == 0 or len(synth) == 0:
        raise ValueError("‚ùå No real or synthetic entries found. Check the 'type' column content.")

    print(f"üìä Loaded {len(real)} real and {len(synth)} synthetic samples for comparison.\n")

    # ------------------------------------------------------------------
    # üî¨ Statistical comparison
    # ------------------------------------------------------------------
    metrics = ["mean_k", "mean_dp/dy", "flowrate", "porosity", "anisotropy"]
    results = []

    for metric in metrics:
        real_vals = real[metric].dropna().values
        synth_vals = synth[metric].dropna().values

        t_p = ttest_ind(real_vals, synth_vals, equal_var=False).pvalue
        ks_p = ks_2samp(real_vals, synth_vals).pvalue

        results.append({
            "Metric": metric,
            "real_mean": np.mean(real_vals),
            "synthetic_mean": np.mean(synth_vals),
            "t_p_value": t_p,
            "ks_p_value": ks_p
        })

    results_df = pd.DataFrame(results)

    # ------------------------------------------------------------------
    # üíæ Save results
    # ------------------------------------------------------------------
    out_path = "results/physics_validation_report.csv"
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    results_df.to_csv(out_path, index=False)

    # ------------------------------------------------------------------
    # üåø Summary report
    # ------------------------------------------------------------------
    print("üßæ Physics validation report saved ‚Üí results/physics_validation_report.csv\n")

    sig_t = (results_df["t_p_value"] > 0.05).sum()
    sig_ks = (results_df["ks_p_value"] > 0.05).sum()

    print("üåø Flow Physics Validation Summary")
    print("-----------------------------------")
    print(f"‚úÖ Metrics analyzed: {len(metrics)}")
    print(f"‚úÖ Metrics statistically similar (T-test): {sig_t}/{len(metrics)}")
    print(f"‚úÖ Metrics distribution-similar (KS-test): {sig_ks}/{len(metrics)}\n")

    print("üìä Detailed Metric Comparison:\n")
    print(results_df.to_string(index=False, float_format="%.5f"))

    print("\nüéØ Interpretation:")
    print("- p > 0.05 ‚áí statistically similar (no significant difference).")
    print("- p ‚â§ 0.05 ‚áí statistically different (model may need refinement).")

if __name__ == "__main__":
    analyze_flow_metrics()


========== FILE: src/analyze_latent.py ==========

"""
analyze_latent.py
Visualize the learned latent space of the XylemAutoencoder.
Works with dynamic-layer model version (auto-initializing architecture).
"""

import os, sys, subprocess

# --- Auto-install missing dependencies ---
REQUIRED = ["torch", "torchvision", "numpy", "matplotlib",
            "Pillow", "scikit-learn", "umap-learn"]
for pkg in REQUIRED:
    try:
        __import__(pkg.replace("-", "_"))
    except ImportError:
        print(f"Installing missing package: {pkg}")
        subprocess.check_call([sys.executable, "-m", "pip", "install", pkg])

# --- Imports ---
import numpy as np
import torch
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
import umap

# --- Path setup ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(CURRENT_DIR)
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

# --- Import model definition ---
try:
    from src.model import XylemAutoencoder
except ModuleNotFoundError:
    import model
    XylemAutoencoder = model.XylemAutoencoder

# --- Config ---
DATA_DIR = os.path.join(ROOT_DIR, "data", "generated_microtubes")
MODEL_PATH = os.path.join(ROOT_DIR, "results", "xylem_autoencoder.pt")
RESULTS_DIR = os.path.join(ROOT_DIR, "results", "latent_analysis")
os.makedirs(RESULTS_DIR, exist_ok=True)
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# --- Dataset loader ---
class XylemDataset(Dataset):
    def __init__(self, path):
        self.files = sorted([f for f in os.listdir(path) if f.endswith(".png")])
        self.transform = transforms.Compose([
            transforms.Grayscale(),
            transforms.Resize((256, 256)),
            transforms.ToTensor()
        ])
    def __len__(self):
        return len(self.files)
    def __getitem__(self, idx):
        img = Image.open(os.path.join(DATA_DIR, self.files[idx]))
        return self.transform(img), self.files[idx]

# --- Load model + initialize layers before loading weights ---
model = XylemAutoencoder(latent_dim=32).to(DEVICE)

# Force layer initialization with dummy input
with torch.no_grad():
    _ = model(torch.zeros(1, 1, 256, 256).to(DEVICE))

# Load trained weights (allow partial mismatch)
state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
missing, unexpected = model.load_state_dict(state_dict, strict=False)
print(f"Loaded weights. Missing keys: {missing}, Unexpected keys: {unexpected}")

model.eval()

# --- Load data ---
dataset = XylemDataset(DATA_DIR)
loader = DataLoader(dataset, batch_size=1, shuffle=False)

# --- Encode all images into latent vectors ---
latents, names = [], []
with torch.no_grad():
    for imgs, fns in loader:
        imgs = imgs.to(DEVICE)
        _, z = model(imgs)
        latents.append(z.cpu().numpy())
        names += fns
latents = np.vstack(latents)
print(f"Extracted latent vectors: {latents.shape}")

# --- Compute 2D projections ---
tsne = TSNE(n_components=2, perplexity=5, random_state=42).fit_transform(latents)
umap_proj = umap.UMAP(n_neighbors=5, min_dist=0.3,
                      metric="euclidean", random_state=42).fit_transform(latents)

# --- Plot t-SNE ---
plt.figure(figsize=(6, 5))
plt.scatter(tsne[:, 0], tsne[:, 1],
            c=np.arange(len(latents)), cmap="viridis", s=60)
for i, name in enumerate(names):
    plt.text(tsne[i, 0], tsne[i, 1],
             name.replace("xylem_", "").replace(".png", ""),
             fontsize=8)
plt.title("t-SNE of latent space")
plt.tight_layout()
plt.savefig(os.path.join(RESULTS_DIR, "latent_tsne.png"))
plt.close()

# --- Plot UMAP ---
plt.figure(figsize=(6, 5))
plt.scatter(umap_proj[:, 0], umap_proj[:, 1],
            c=np.arange(len(latents)), cmap="plasma", s=60)
for i, name in enumerate(names):
    plt.text(umap_proj[i, 0], umap_proj[i, 1],
             name.replace("xylem_", "").replace(".png", ""),
             fontsize=8)
plt.title("UMAP of latent space")
plt.tight_layout()
plt.savefig(os.path.join(RESULTS_DIR, "latent_umap.png"))
plt.close()

print(f"‚úÖ Latent analysis complete. Plots saved to {RESULTS_DIR}")


========== FILE: src/analyze_morphology.py ==========

"""
analyze_morphology.py
Correlates geometric features of generated/optimized xylem structures
with their simulated hydraulic conductivity.
"""

import os, sys, glob, subprocess
import numpy as np
import matplotlib.pyplot as plt
from skimage.io import imread
from skimage.measure import label, regionprops
from scipy.ndimage import distance_transform_edt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Dependencies check
REQUIRED = ["numpy", "matplotlib", "scikit-image", "scipy", "scikit-learn"]
for pkg in REQUIRED:
    try:
        __import__(pkg)
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install", pkg])

# Paths
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(CURRENT_DIR)
DATA_DIR = os.path.join(ROOT_DIR, "data", "generated_microtubes")
OPT_DIR = os.path.join(ROOT_DIR, "results", "optimization")
OUT_DIR = os.path.join(ROOT_DIR, "results", "morphology_analysis")
os.makedirs(OUT_DIR, exist_ok=True)

# --- Utility functions ---

def porosity(img):
    return np.mean(img > 0.5)

def mean_diameter(img):
    dist = distance_transform_edt(img > 0.5)
    return np.mean(dist[img > 0.5]) * 2  # mean diameter ‚âà mean distance * 2

def connectivity(img):
    labeled = label(img > 0.5)
    return len(np.unique(labeled)) - 1  # number of connected regions

def tortuosity(img):
    # approximate tortuosity via skeleton-to-Euclidean ratio
    from skimage.morphology import skeletonize
    skel = skeletonize(img > 0.5)
    path_len = np.sum(skel)
    direct_len = np.sqrt(img.shape[0]**2 + img.shape[1]**2)
    return path_len / direct_len

def analyze_folder(folder):
    files = sorted(glob.glob(os.path.join(folder, "*.png")))
    features = []
    for f in files:
        img = imread(f, as_gray=True)
        img = img / 255.0 if img.max() > 1 else img
        features.append([
            porosity(img),
            mean_diameter(img),
            connectivity(img),
            tortuosity(img)
        ])
    return np.array(features), [os.path.basename(f) for f in files]

# --- Load data ---
base_feats, base_names = analyze_folder(DATA_DIR)
opt_feats, opt_names = analyze_folder(OPT_DIR)

# --- Fake conductivity data (from filenames or previous runs) ---
# Placeholder: in your full workflow, read conductivity from simulator logs
np.random.seed(42)
base_cond = np.random.rand(len(base_feats)) * 0.03 + 0.02
opt_cond = np.random.rand(len(opt_feats)) * 0.03 + 0.05

# --- Combine ---
X = np.vstack([base_feats, opt_feats])
y = np.concatenate([base_cond, opt_cond])
labels = ["porosity", "mean_diameter", "connectivity", "tortuosity"]

# --- Plot correlations ---
for i, name in enumerate(labels):
    plt.figure()
    plt.scatter(X[:, i], y, c=["blue"]*len(base_feats) + ["red"]*len(opt_feats), alpha=0.7)
    plt.xlabel(name)
    plt.ylabel("conductivity")
    plt.title(f"{name} vs conductivity")
    plt.grid(True)
    plt.savefig(os.path.join(OUT_DIR, f"{name}_vs_conductivity.png"))
    plt.close()

# --- Simple regression analysis ---
reg = LinearRegression().fit(X, y)
y_pred = reg.predict(X)
r2 = r2_score(y, y_pred)
print(f"‚úÖ Morphology analysis complete. R¬≤ = {r2:.3f}")
print(f"Feature importances (coefficients):")
for name, coef in zip(labels, reg.coef_):
    print(f"  {name}: {coef:.5f}")
print(f"Results saved to {OUT_DIR}")


========== FILE: src/analyze_tradeoff.py ==========

"""
analyze_tradeoff.py

Phase 2: Flow vs. Stiffness trade-off study.

- Loads results/flow_metrics/flow_metrics.csv
- Filters to synthetic samples
- Uses Porosity to define:
    density = 1 - porosity
    stiffness_potential = (density ** 2)
- Normalizes both axes:
    x = Relative Flow Rate (Q / Q_max)
    y = Normalized Stiffness Potential (E / E_solid)
- Saves scatter plot to results/flow_stiffness_tradeoff.png
- Prints top candidate designs by (flow * stiffness) score
"""

import os
from pathlib import Path

import pandas as pd
import matplotlib.pyplot as plt


ROOT = Path(__file__).resolve().parents[1]
METRICS_PATH = ROOT / "results" / "flow_metrics" / "flow_metrics.csv"
OUT_PLOT = ROOT / "results" / "flow_stiffness_tradeoff.png"
OUT_CSV = ROOT / "results" / "flow_stiffness_candidates.csv"


def main():
    if not METRICS_PATH.exists():
        raise FileNotFoundError(
            f"Could not find {METRICS_PATH}. "
            "Run flow_simulation.py first."
        )

    df = pd.read_csv(METRICS_PATH)

    # Expect columns: Mean_K, Mean_dP/dy, FlowRate, Porosity, Anisotropy, Type
    required_cols = {"FlowRate", "Porosity", "Type"}
    missing = required_cols - set(df.columns)
    if missing:
        raise ValueError(f"Missing expected columns in flow_metrics.csv: {missing}")

    # Filter to synthetic structures only
    mask_syn = df["Type"].astype(str).str.lower() == "synthetic"
    df_syn = df[mask_syn].copy()
    if df_syn.empty:
        raise RuntimeError("No synthetic samples found (Type == 'synthetic').")

    # Porosity is assumed to be a fraction in [0, 1].
    # Quick sanity check; if you see ~10‚Äì50, it is likely in percent.
    por_min = df_syn["Porosity"].min()
    por_max = df_syn["Porosity"].max()
    print(f"Porosity range (synthetic): [{por_min:.4f}, {por_max:.4f}]")

    # If you *know* it's in percent, you could uncomment this:
    # if por_max > 1.0:
    #     df_syn["Porosity"] = df_syn["Porosity"] / 100.0

    porosity = df_syn["Porosity"].values
    density = 1.0 - porosity

    # Stiffness potential heuristic: E ‚àù œÅ^2
    stiffness_raw = density ** 2

    # Normalize to make axes unitless and comparable
    stiffness_norm = stiffness_raw / stiffness_raw.max()

    flow_raw = df_syn["FlowRate"].values
    flow_norm = flow_raw / flow_raw.max()

    df_syn["density"] = density
    df_syn["stiffness_potential"] = stiffness_raw
    df_syn["stiffness_norm"] = stiffness_norm
    df_syn["flow_norm"] = flow_norm

    # Simple combined score to find "interesting" candidates:
    # high flow *and* high stiffness.
    df_syn["score_flow_x_stiffness"] = df_syn["flow_norm"] * df_syn["stiffness_norm"]
    df_syn_sorted = df_syn.sort_values(
        "score_flow_x_stiffness", ascending=False
    ).reset_index(drop=True)

    # Save top candidates to CSV for inspection
    top_k = 10
    df_syn_sorted.head(top_k).to_csv(OUT_CSV, index=False)
    print(f"‚úÖ Saved top {top_k} candidate designs ‚Üí {OUT_CSV}")

    # Scatter plot: Flow vs. Stiffness
    plt.figure(figsize=(6, 5))
    plt.scatter(
        df_syn["flow_norm"],
        df_syn["stiffness_norm"],
        alpha=0.4,
        s=15,
        label="Synthetic samples",
    )

    # Highlight top-k on the plot
    top = df_syn_sorted.head(top_k)
    plt.scatter(
        top["flow_norm"],
        top["stiffness_norm"],
        s=40,
        edgecolors="black",
        linewidths=0.7,
        label=f"Top {top_k} (flow √ó stiffness)",
    )

    plt.xlabel("Relative Flow Rate  (Q / Q_max)")
    plt.ylabel("Normalized Stiffness Potential  (E / E_solid)")
    plt.title("Flow‚ÄìStiffness Trade-off for Synthetic Microstructures")
    plt.legend()
    plt.tight_layout()

    os.makedirs(OUT_PLOT.parent, exist_ok=True)
    plt.savefig(OUT_PLOT, dpi=200)
    print(f"‚úÖ Trade-off plot saved ‚Üí {OUT_PLOT}")

    # Print a small text summary of the top candidates
    print("\nTop candidate designs (by flow √ó stiffness score):")
    cols_to_show = [
        "FlowRate",
        "Porosity",
        "density",
        "stiffness_potential",
        "flow_norm",
        "stiffness_norm",
        "score_flow_x_stiffness",
    ]
    print(df_syn_sorted[cols_to_show].head(top_k).to_string(index=False))


if __name__ == "__main__":
    main()


========== FILE: src/audit_efficiency.py ==========

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# CONFIG
AI_IMAGE_PATH = "results/thermal_design/MaxCooling_Heavy_structure.png"
OUTPUT_DIR = "results/efficiency_audit/"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ---------------------------------------------------------
# 1. The Physics (Simplified Fluid Solver)
# ---------------------------------------------------------
def solve_flow_resistance(binary_img, max_iter=2000):
    """
    Estimates fluid resistance using a simplified Darcy-Stokes proxy.
    Solve P (Pressure) field: Div(K * Grad(P)) = 0
    where K is high in Void and 0 in Solid.
    
    This is effectively the same math as Heat, but interpreted as Pressure.
    Flux = Flow Rate.
    Resistance = Pressure Drop / Flow Rate.
    """
    h, w = binary_img.shape
    
    # Material Permeability
    # Void (1) = High Permeability (Flows easily)
    # Solid (0) = Near-Zero Permeability (Blocked)
    K_VOID = 1.0
    K_SOLID = 1e-6 # Nearly blocked
    
    # Map image to Permeability Field
    # Assuming Binary: 1=Void, 0=Solid
    k_map = np.where(binary_img > 0.5, K_VOID, K_SOLID)
    
    # Initialize Pressure Field (Linear gradient Left->Right)
    P = np.linspace(1.0, 0.0, w)
    P = np.tile(P, (h, 1))
    
    # Iterative Solver (Finite Difference)
    for i in range(max_iter):
        P_old = P.copy()
        
        # Simple Neighbor Average weighted by Permeability (k)
        # This is a proxy for P_new = (P_neighbors) 
        # Correct physics would use face-centered velocities, 
        # but this diffuses Pressure correctly for a resistance metric.
        
        P[1:-1, 1:-1] = 0.25 * (
            P_old[0:-2, 1:-1] + 
            P_old[2:, 1:-1] + 
            P_old[1:-1, 0:-2] + 
            P_old[1:-1, 2:]
        )
        
        # Boundary Conditions (Left=High P, Right=Low P)
        P[:, 0] = 1.0
        P[:, -1] = 0.0
        # Insulated Walls (Top/Bottom)
        P[0, :] = P[1, :]
        P[-1, :] = P[-2, :]
        
    # Calculate Flow Rate (Flux)
    # Q = -k * dP/dx at the outlet
    dPdx = P[:, -1] - P[:, -2]
    flux = np.sum(-k_map[:, -1] * dPdx)
    
    # Resistance = Pressure Drop / Flux
    # dP = 1.0
    resistance = 1.0 / (flux + 1e-9)
    
    return resistance, P

# ---------------------------------------------------------
# 2. Generators & Loaders
# ---------------------------------------------------------
def generate_random_noise(shape=(256, 256), density=0.6):
    """Generates the high-performing 'Random' baseline"""
    # Random 0.0 - 1.0
    noise = np.random.rand(*shape)
    # Threshold: We want 'density' fraction to be SOLID (0)
    # So if noise < density -> Solid. Else -> Void (1)
    binary = np.ones(shape)
    binary[noise < density] = 0.0
    return binary

def load_ai_design(path):
    if not os.path.exists(path):
        print(f"‚ö†Ô∏è AI Image not found: {path}")
        return None
    img = Image.open(path).convert('L')
    arr = np.array(img).astype(np.float32) / 255.0
    
    # Normalize and Threshold
    # In your thermal plots, 'inferno' likely saved Dark=Low, Light=High
    # We need Void=1, Solid=0.
    # Usually Xylem AI: Bright=Void.
    binary = arr > 0.5
    return binary.astype(float)

# ---------------------------------------------------------
# 3. The Showdown
# ---------------------------------------------------------
def main():
    print("‚öîÔ∏è  AUDIT: Flow Resistance Showdown")
    
    # 1. Load AI Candidate
    print(f"   Loading AI Design: {AI_IMAGE_PATH}")
    ai_img = load_ai_design(AI_IMAGE_PATH)
    if ai_img is None:
        print("   -> Using Placeholder AI (Error loading)")
        ai_img = np.zeros((256,256))
        
    # 2. Generate Random Baseline (The "Winner" of Thermal)
    print("   Generating Random Noise (Density=0.6)...")
    rand_img = generate_random_noise(density=0.6)
    
    # 3. Simulate Flow
    print("   üåä Simulating Flow (Calculating Resistance)...")
    res_ai, p_ai = solve_flow_resistance(ai_img)
    print(f"      AI Resistance: {res_ai:.4f}")
    
    res_rand, p_rand = solve_flow_resistance(rand_img)
    print(f"      Random Resistance: {res_rand:.4f}")
    
    # 4. The Verdict
    ratio = res_rand / res_ai
    print("\nüèÜ THE VERDICT:")
    if ratio > 1.0:
        print(f"   ‚úÖ The AI Design flows {ratio:.1f}x BETTER than Random Noise.")
        print("   Conclusion: Random Noise cools well but clogs the pump.")
        print("   AI Design balances cooling with flow efficiency.")
    else:
        print(f"   ‚ùå Random Noise flows {1/ratio:.1f}x better. (Unexpected!)")
        
    # 5. Visualize
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(p_ai, cmap='Blues')
    plt.title(f"AI Flow Field\nRes = {res_ai:.2f}")
    plt.axis('off')
    
    plt.subplot(1, 2, 2)
    plt.imshow(p_rand, cmap='Blues')
    plt.title(f"Random Noise Flow Field\nRes = {res_rand:.2f}")
    plt.axis('off')
    
    save_path = os.path.join(OUTPUT_DIR, "flow_resistance_audit.png")
    plt.savefig(save_path)
    print(f"   üìä Flow maps saved to {save_path}")

if __name__ == "__main__":
    main()

========== FILE: src/benchmark_baselines.py ==========

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
from tqdm import tqdm

# CONFIG
OUTPUT_DIR = "results/baselines/"
AI_METRICS_PATH = "results/thermal_metrics/thermal_metrics.csv" # Your AI results
os.makedirs(OUTPUT_DIR, exist_ok=True)

# PHYSICS CONSTANTS (Must match heat_simulation.py)
VOID_THRESHOLD = 0.60
K_SOLID = 1.0
K_VOID = 0.05
T_HOT = 1.0
T_COLD = 0.0
HOT_STRIP_WIDTH = 5

# ---------------------------------------------------------
# 1. Baseline Generators
# ---------------------------------------------------------

def generate_vertical_fins(shape=(256, 256), num_fins=10, thickness=5):
    """Straight vertical lines (Standard Heat Sink)"""
    img = np.ones(shape) # Start with Void (White=1.0)
    spacing = shape[1] // num_fins
    for i in range(num_fins):
        x = i * spacing + (spacing // 2)
        img[:, x:x+thickness] = 0.0 # Solid (Black=0.0)
    return img

def generate_grid(shape=(256, 256), num_cells=8, thickness=2):
    """Cross-hatch grid"""
    img = np.ones(shape)
    step = shape[0] // num_cells
    # Vertical lines
    for x in range(0, shape[1], step):
        img[:, x:x+thickness] = 0.0
    # Horizontal lines
    for y in range(0, shape[0], step):
        img[y:y+thickness, :] = 0.0
    return img

def generate_random_noise(shape=(256, 256), density=0.4):
    """Random porous media"""
    return np.random.choice([0.0, 1.0], size=shape, p=[density, 1-density])

# ---------------------------------------------------------
# 2. The Solver (Copied for consistency)
# ---------------------------------------------------------
def solve_steady_heat(k_grid, max_iters=2000):
    H, W = k_grid.shape
    T = np.linspace(1.0, 0.0, W); T = np.tile(T, (H, 1)) # Linear init
    T[:, 0] = T_HOT; T[:, -1] = T_COLD

    for _ in range(max_iters):
        # Fast Vectorized Gauss-Seidel Approximation
        T_up, T_down = T[0:-2, 1:-1], T[2:, 1:-1]
        T_left, T_right = T[1:-1, 0:-2], T[1:-1, 2:]
        k_c = k_grid[1:-1, 1:-1]
        
        # Neighbor K (Harmonic Mean)
        eps = 1e-8
        k_n = 2*k_c*k_grid[0:-2, 1:-1]/(k_c+k_grid[0:-2, 1:-1]+eps)
        k_s = 2*k_c*k_grid[2:, 1:-1]/(k_c+k_grid[2:, 1:-1]+eps)
        k_w = 2*k_c*k_grid[1:-1, 0:-2]/(k_c+k_grid[1:-1, 0:-2]+eps)
        k_e = 2*k_c*k_grid[1:-1, 2:]/(k_c+k_grid[1:-1, 2:]+eps)
        
        T[1:-1, 1:-1] = (k_n*T_up + k_s*T_down + k_w*T_left + k_e*T_right) / (k_n+k_s+k_w+k_e+eps)
        
        # BCs
        T[:, 0] = T_HOT; T[:, -1] = T_COLD
        T[0, :] = T[1, :]; T[-1, :] = T[-2, :] # Insulated Top/Bottom
        
    return T

def evaluate_design(img, name):
    # Map to K
    # Img: 1.0=Void, 0.0=Solid
    k_map = np.where(img < 0.5, K_SOLID, K_VOID)
    
    # Solve
    T = solve_steady_heat(k_map)
    
    # Metrics
    dTdx = T[:, -1] - T[:, -2]
    flux = np.sum(-k_map[:, -1] * dTdx)
    density = np.mean(img < 0.5)
    
    return {"name": name, "flux": flux, "density": density}

# ---------------------------------------------------------
# 3. Execution & Plotting
# ---------------------------------------------------------
def main():
    print("üß™ Generative AI vs. Engineering Baselines...")
    results = []
    
    # 1. Run Baselines
    # Generate a spectrum of fins (sparse to dense)
    for n in [5, 10, 20, 40, 60]: 
        img = generate_vertical_fins(num_fins=n, thickness=4)
        results.append(evaluate_design(img, f"Fins_{n}"))
        
    # Generate a spectrum of grids
    for n in [4, 8, 16, 32]:
        img = generate_grid(num_cells=n, thickness=2)
        results.append(evaluate_design(img, f"Grid_{n}"))
        
    # Generate random noise (The "Bad" Baseline)
    for d in [0.2, 0.4, 0.6]:
        img = generate_random_noise(density=d)
        results.append(evaluate_design(img, f"Random_{d}"))

    base_df = pd.DataFrame(results)
    base_df.to_csv(os.path.join(OUTPUT_DIR, "baseline_metrics.csv"), index=False)
    print("‚úÖ Baselines Simulated.")

    # 2. Load AI Results
    if os.path.exists(AI_METRICS_PATH):
        ai_df = pd.read_csv(AI_METRICS_PATH)
        # Normalize names for plotting
        ai_flux = ai_df['Q_total']
        ai_dens = ai_df['rho_solid']
    else:
        print("‚ö†Ô∏è  Warning: AI metrics not found. Plotting baselines only.")
        ai_df = None

    # 3. The Showdown Plot
    plt.figure(figsize=(10, 6))
    
    # Plot Baselines
    plt.scatter(base_df['density'], base_df['flux'], c='gray', marker='x', s=100, label='Standard Engineering (Fins/Grids)')
    
    # Plot AI
    if ai_df is not None:
        plt.scatter(ai_dens, ai_flux, c=ai_flux, cmap='inferno', alpha=0.6, label='AI Generative Design')
        plt.colorbar(label='Heat Flux')
    
    plt.title("Performance Frontier: Generative Coral vs. Standard Fins", fontsize=14)
    plt.xlabel("Material Density (Cost/Weight)", fontsize=12)
    plt.ylabel("Heat Flux (Cooling Performance)", fontsize=12)
    plt.grid(True, alpha=0.3)
    plt.legend()
    
    save_path = os.path.join(OUTPUT_DIR, "performance_frontier.png")
    plt.savefig(save_path, dpi=150)
    print(f"üìä Comparison Plot saved to {save_path}")

if __name__ == "__main__":
    main()

========== FILE: src/benchmark_multiphysics.py ==========

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
from src.benchmark_baselines import generate_vertical_fins, generate_grid, generate_random_noise, solve_steady_heat
from src.audit_efficiency import solve_flow_resistance, load_ai_design

OUTPUT_DIR = "results/baselines/"
AI_IMAGE_PATH = "results/thermal_design/MaxCooling_Heavy_structure.png"

def get_metrics(img, name):
    # 1. Thermal
    k_map = np.where(img < 0.5, 1.0, 0.05) # Solid=1, Void=0.05
    T = solve_steady_heat(k_map)
    dTdx = T[:, -1] - T[:, -2]
    flux = np.sum(-k_map[:, -1] * dTdx)
    
    # 2. Flow Resistance
    # Invert for flow: Void(1) is high permeability
    # Binary: 1=Void, 0=Solid
    binary_void = (img > 0.5).astype(float)
    res, _ = solve_flow_resistance(binary_void)
    
    return {"name": name, "flux": flux, "resistance": res, "type": "baseline"}

def main():
    print("‚öîÔ∏è  Running Multi-Physics Showdown...")
    data = []
    
    # 1. Baselines
    print("   Simulating Fins...")
    for n in [10, 20, 40]:
        img = generate_vertical_fins(num_fins=n, thickness=4)
        data.append(get_metrics(img, f"Fins_{n}"))
        
    print("   Simulating Grids...")
    for n in [8, 16, 32]:
        img = generate_grid(num_cells=n, thickness=2)
        data.append(get_metrics(img, f"Grid_{n}"))
        
    print("   Simulating Random...")
    for d in [0.4, 0.6]:
        img = generate_random_noise(density=d)
        data.append(get_metrics(img, f"Random_{d}"))
        
    # 2. Your AI Design
    print("   Simulating AI...")
    ai_img = load_ai_design(AI_IMAGE_PATH)
    if ai_img is not None:
        # ai_img is already 1=Void, 0=Solid? 
        # Check load_ai_design in audit_efficiency. It returns Binary Void=1.
        # We need to invert it for get_metrics which expects Image (White=Void, Black=Solid)?
        # Actually get_metrics logic: img < 0.5 is SOLID. 
        # load_ai_design returns binary where 1=VOID. 
        # So we pass it directly? No, let's just run solvers directly to be safe.
        
        # Thermal (Needs K map)
        k_map_ai = np.where(ai_img < 0.5, 1.0, 0.05) # If 1=Void, <0.5 is False -> Solid? 
        # Wait, if ai_img is 1=Void, then ai_img < 0.5 selects 0 (Solid). Correct.
        T_ai = solve_steady_heat(k_map_ai)
        dTdx_ai = T_ai[:, -1] - T_ai[:, -2]
        flux_ai = np.sum(-k_map_ai[:, -1] * dTdx_ai)
        
        # Flow (Needs Binary Void)
        res_ai, _ = solve_flow_resistance(ai_img)
        
        data.append({"name": "AI_Coral", "flux": flux_ai, "resistance": res_ai, "type": "AI"})

    # 3. Plot
    df = pd.DataFrame(data)
    print(df)
    
    plt.figure(figsize=(8,6))
    
    # Plot Baselines
    bases = df[df['type'] == 'baseline']
    plt.scatter(bases['resistance'], bases['flux'], c='gray', label='Baselines')
    
    # Label Baselines
    for _, row in bases.iterrows():
        plt.text(row['resistance'], row['flux'], "  "+row['name'], fontsize=8)
        
    # Plot AI
    ai = df[df['type'] == 'AI']
    plt.scatter(ai['resistance'], ai['flux'], c='red', s=100, label='AI Generative')
    
    plt.xlabel("Flow Resistance (Lower is Better)")
    plt.ylabel("Heat Flux (Higher is Better)")
    plt.title("The Multi-Physics Pareto Front")
    plt.grid(True, alpha=0.3)
    plt.legend()
    plt.savefig(os.path.join(OUTPUT_DIR, "multiphysics_frontier.png"))
    print("\n‚úÖ Chart saved: results/baselines/multiphysics_frontier.png")

if __name__ == "__main__":
    main()

========== FILE: src/build_surrogate_dataset.py ==========

import os
from typing import List

import numpy as np
import pandas as pd
from PIL import Image
import torch


REAL_DIR = "data/real_xylem_preprocessed"
SYN_DIR = "data/generated_microtubes"
METRICS_CSV = "results/flow_metrics/flow_metrics.csv"
OUT_PATH = "results/surrogate_dataset.pt"

METRIC_COLS = ["Mean_K", "Mean_dP/dy", "FlowRate", "Porosity", "Anisotropy"]


def list_pngs(root: str) -> List[str]:
    """Return sorted list of PNG paths inside a directory."""
    files = [f for f in os.listdir(root) if f.lower().endswith(".png")]
    files.sort()
    return [os.path.join(root, f) for f in files]


def load_image(path: str) -> torch.Tensor:
    """Load 256x256 grayscale image and normalize to [0, 1]."""
    img = Image.open(path).convert("L")
    # Your preprocessed images should already be 256√ó256, but this is cheap insurance.
    img = img.resize((256, 256))
    arr = np.array(img, dtype=np.float32) / 255.0  # (H, W)
    tensor = torch.from_numpy(arr).unsqueeze(0)     # (1, H, W)
    return tensor


def build_surrogate_dataset() -> None:
    # ----- 1. Load solver metrics -----
    if not os.path.exists(METRICS_CSV):
        raise FileNotFoundError(f"Missing {METRICS_CSV}. Run flow_simulation.py first.")

    df = pd.read_csv(METRICS_CSV)

    for col in METRIC_COLS + ["Type"]:
        if col not in df.columns:
            raise RuntimeError(f"Column '{col}' not found in {METRICS_CSV}")

    df_real = df[df["Type"] == "real"].reset_index(drop=True)
    df_syn = df[df["Type"] == "synthetic"].reset_index(drop=True)

    # ----- 2. Collect images in the SAME order as flow_simulation.py -----
    real_paths = list_pngs(REAL_DIR)
    syn_paths = list_pngs(SYN_DIR)

    if len(real_paths) != len(df_real):
        print(f"‚ö†Ô∏è real image count ({len(real_paths)}) != real metrics rows ({len(df_real)})")
    if len(syn_paths) != len(df_syn):
        print(f"‚ö†Ô∏è synthetic image count ({len(syn_paths)}) != synthetic metrics rows ({len(df_syn)})")

    all_images = []
    all_metrics = []

    # Real first, then synthetic ‚Äî this matches how flow_simulation writes the CSV
    for img_path, (_, row) in zip(real_paths, df_real[METRIC_COLS].iterrows()):
        img_t = load_image(img_path)
        all_images.append(img_t)
        all_metrics.append(torch.from_numpy(row.values.astype(np.float32)))

    for img_path, (_, row) in zip(syn_paths, df_syn[METRIC_COLS].iterrows()):
        img_t = load_image(img_path)
        all_images.append(img_t)
        all_metrics.append(torch.from_numpy(row.values.astype(np.float32)))

    if not all_images:
        raise RuntimeError("No images collected; cannot build surrogate dataset")

    images_tensor = torch.stack(all_images, dim=0)   # (N, 1, H, W)
    metrics_tensor = torch.stack(all_metrics, dim=0) # (N, 5)

    # ----- 3. Save dataset -----
    torch.save(
        {
            "images": images_tensor,
            "metrics": metrics_tensor,
            "metric_names": METRIC_COLS,
        },
        OUT_PATH,
    )

    print("‚úÖ Built surrogate dataset")
    print("   images: ", images_tensor.shape)
    print("   metrics:", metrics_tensor.shape)
    print("   saved ‚Üí ", OUT_PATH)


if __name__ == "__main__":
    build_surrogate_dataset()


========== FILE: src/check_real_porosity.py ==========

import os
from PIL import Image
import numpy as np

DATA_DIR = "data/real_xylem_preprocessed"

files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(".png")]
files = sorted(files)[:10]

print(f"Checking {len(files)} images from {DATA_DIR}...")

means = []
for fname in files:
    path = os.path.join(DATA_DIR, fname)
    img = Image.open(path).convert("L")
    arr = np.array(img, dtype=np.float32) / 255.0  # 0‚Äì1
    m = float(arr.mean())
    means.append(m)
    print(f"{fname}: mean pixel = {m:.4f}")

if means:
    print(f"\nAverage of means: {np.mean(means):.4f}")
import pandas as pd

csv_path = "results/flow_metrics/flow_metrics.csv"
df = pd.read_csv(csv_path)

# Adjust these if your column names differ
name_col = [c for c in df.columns if "file" in c.lower()][0]
poro_col = [c for c in df.columns if "porosity" in c.lower()][0]

mask = df[name_col].isin(
    ["F02a.png","F02b.png","F02c.png","F02d.png","F02e.png",
     "F03a.png","F03b.png","F03c.png","F03d.png","F03e.png"]
)

print(df.loc[mask, [name_col, poro_col]])
print("\nMean solver porosity on those:", df.loc[mask, poro_col].mean())


========== FILE: src/check_solver_porosity.py ==========

import pandas as pd

df = pd.read_csv("results/flow_metrics/flow_metrics.csv")
print("Columns:", list(df.columns))
print(df.head())

if "Type" in df.columns and "Porosity" in df.columns:
    print("\nPorosity by Type:")
    print(df.groupby("Type")["Porosity"].describe())
else:
    print("\nNo 'Type' or 'Porosity' column found; got:", df.columns.tolist())


========== FILE: src/compare_physics_reports.py ==========

import pandas as pd
import os

# --------------------------
# CONFIG
# --------------------------
BASELINE_PATH = "results/physics_validation_report.csv"  # pre-tuning
NEW_PATH = "results/physics_validation_report_post_tuned.csv"  # post-tuning

if not os.path.exists(BASELINE_PATH):
    raise FileNotFoundError("Baseline file not found. Run analyze_flow_metrics.py first.")
if not os.path.exists(NEW_PATH):
    raise FileNotFoundError("New tuned report not found. Run analyze_flow_metrics.py again after retraining.")

# --------------------------
# LOAD AND COMPARE
# --------------------------
base = pd.read_csv(BASELINE_PATH, index_col=0)
new = pd.read_csv(NEW_PATH, index_col=0)

comparison = pd.DataFrame({
    "Real Mean": base["real_mean"],
    "Synthetic (Before)": base["synthetic_mean"],
    "Synthetic (After)": new["synthetic_mean"],
    "Œî Mean Improvement": new["synthetic_mean"] - base["synthetic_mean"],
    "T-Test p Before": base["t_p_value"],
    "T-Test p After": new["t_p_value"],
    "KS-Test p Before": base["ks_p_value"],
    "KS-Test p After": new["ks_p_value"],
})

# Improvement summary
improved_t = (comparison["T-Test p After"] > comparison["T-Test p Before"]).sum()
improved_ks = (comparison["KS-Test p After"] > comparison["KS-Test p Before"]).sum()

print("\nüåø Physics-Informed Training Effect Summary")
print("--------------------------------------------")
print(f"‚úÖ Metrics improved (T-test): {improved_t}/{len(comparison)}")
print(f"‚úÖ Metrics improved (KS-test): {improved_ks}/{len(comparison)}")
print("\nüìä Detailed Comparison:\n")
print(comparison.round(5))

# Save
comparison.to_csv("results/physics_comparison_report.csv")
print("\n‚úÖ Saved detailed report ‚Üí results/physics_comparison_report.csv")


========== FILE: src/export_to_3d.py ==========

import os
import numpy as np
import trimesh
from skimage import measure
from PIL import Image
import matplotlib.pyplot as plt

# CONFIG
# We will use the 'gradient beam' image you just generated
INPUT_IMAGE = "results/gradient_beam/beam_structure.png" 
OUTPUT_STL = "results/gradient_beam/gradient_beam_3d.stl"
EXTRUSION_HEIGHT = 50  # How thick is the beam? (Number of layers)
VOXEL_SIZE = 1.0       # Size of one pixel in mm (Scale factor)

def load_and_process_image(path):
    if not os.path.exists(path):
        print(f"‚ùå Error: Image not found at {path}")
        return None
    
    # Load image, convert to grayscale
    img = Image.open(path).convert('L')
    img_arr = np.array(img).astype(np.float32) / 255.0
    
    # Threshold: Solid is typically Dark (0.0) in your plots.
    # Let's check: In 'beam_structure.png', did you plot Solids as Black?
    # If yes, we want pixels < 0.5 to be TRUE (Solid).
    # Adjust this threshold based on your visual inspection of the PNG.
    binary_slice = img_arr < 0.5 
    
    return binary_slice

def create_voxel_volume(binary_slice, depth):
    print(f"üî® Extruding 2D slice ({binary_slice.shape}) to {depth} layers...")
    
    # Stack the 2D slice 'depth' times to make a 3D block
    volume = np.stack([binary_slice] * depth, axis=0)
    
    # Optional: Add a "Floor" (Base Plate) so it prints easily
    # We set the bottom 2 layers to be completely solid (True)
    volume[0:2, :, :] = True
    
    return volume

def export_stl(volume, output_path):
    print("üï∏Ô∏è  Running Marching Cubes (Voxel -> Mesh)...")
    
    # Marching Cubes algorithm (finds the surface of the 3D blob)
    # volume is boolean (True/False). Level=0.5 finds the boundary.
    try:
        verts, faces, normals, values = measure.marching_cubes(volume, level=0.5)
        
        # Scale vertices (Optional)
        verts = verts * VOXEL_SIZE
        
        # Create Mesh object
        mesh = trimesh.Trimesh(vertices=verts, faces=faces)
        
        # Fix normals (make it look smooth)
        mesh.fix_normals()
        
        # Save
        mesh.export(output_path)
        print(f"‚úÖ 3D Mesh saved to: {output_path}")
        print(f"   Vertices: {len(verts)}, Faces: {len(faces)}")
        
    except ValueError:
        print("‚ö†Ô∏è  Error: No surface found. Is the image empty or all solid?")

def main():
    print("üöÄ Starting 2D-to-3D Conversion...")
    
    # 1. Load
    binary_slice = load_and_process_image(INPUT_IMAGE)
    if binary_slice is None: return
    
    # 2. Extrude
    volume = create_voxel_volume(binary_slice, depth=EXTRUSION_HEIGHT)
    
    # 3. Export
    os.makedirs(os.path.dirname(OUTPUT_STL), exist_ok=True)
    export_stl(volume, OUTPUT_STL)
    
    print("\nüéâ DONE. You have escaped Flatland.")
    print("üëâ Next Step: Drag that .stl file into https://www.viewstl.com/ to see it.")

if __name__ == "__main__":
    main()

========== FILE: src/flow_metrics_export.py ==========

"""
flow_metrics_export.py
-------------------------------------
Runs Darcy flow simulation and exports quantitative metrics
for real and synthetic xylem structures.
"""

import os
import csv
import numpy as np
from PIL import Image
from scipy.ndimage import gaussian_filter
from scipy.sparse import diags, linalg

REAL_DIR = "data/real_xylem_preprocessed"
SYN_DIR = "data/generated_microtubes"
SAVE_DIR = "results/flow_metrics"
os.makedirs(SAVE_DIR, exist_ok=True)

IMG_SIZE = (128, 128)
EPS = 1e-6


def load_image(path):
    img = Image.open(path).convert("L").resize(IMG_SIZE)
    return np.array(img, dtype=np.float32) / 255.0


def permeability_map(img):
    return gaussian_filter(img**3 + EPS, sigma=1)


def solve_darcy(k_map, delta_p=1.0, mu=1.0):
    ny, nx = k_map.shape
    N = nx * ny
    kx = (k_map[:, 1:] + k_map[:, :-1]) / 2
    ky = (k_map[1:, :] + k_map[:-1, :]) / 2

    main = np.zeros(N)
    east = np.zeros(N - 1)
    west = np.zeros(N - 1)
    north = np.zeros(N - nx)
    south = np.zeros(N - nx)

    for y in range(ny):
        for x in range(nx):
            i = y * nx + x
            k_e = kx[y, x] if x < nx - 1 else 0
            k_w = kx[y, x - 1] if x > 0 else 0
            k_n = ky[y - 1, x] if y > 0 else 0
            k_s = ky[y, x] if y < ny - 1 else 0
            main[i] = -(k_e + k_w + k_n + k_s)
            if x > 0:
                east[i - 1] = k_e
            if x < nx - 1:
                west[i] = k_w
            if y > 0:
                north[i - nx] = k_n
            if y < ny - 1:
                south[i] = k_s

    A = diags([main, east, west, north, south], [0, -1, 1, -nx, nx], format="csr")

    b = np.zeros(N)
    for x in range(nx):
        b[x] = delta_p * k_map[0, x]

    p = linalg.spsolve(A, b)
    p_field = p.reshape(ny, nx)

    grad_y, grad_x = np.gradient(p_field)
    vx = -k_map * grad_x / mu
    vy = -k_map * grad_y / mu
    return p_field, vx, vy


def porosity(img):
    return np.mean(img)


def anisotropy(img):
    gx, gy = np.gradient(img)
    return np.mean(np.abs(gx)) / (np.mean(np.abs(gy)) + EPS)


def process_folder(folder, label, writer):
    print(f"\nProcessing {label}...")
    files = sorted([f for f in os.listdir(folder) if f.lower().endswith(".png")])
    for f in files:
        path = os.path.join(folder, f)
        img = load_image(path)
        k_map = permeability_map(img)
        p, vx, vy = solve_darcy(k_map)

        flow_rate = np.mean(np.abs(vy))
        mean_k = np.mean(k_map)
        mean_grad = np.mean(np.abs(np.gradient(p)[0]))
        phi = porosity(img)
        aniso = anisotropy(img)

        writer.writerow([label, f, mean_k, mean_grad, flow_rate, phi, aniso])


if __name__ == "__main__":
    csv_path = os.path.join(SAVE_DIR, "flow_metrics.csv")
    with open(csv_path, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["Type", "Filename", "Mean_K", "Mean_dP/dy", "FlowRate", "Porosity", "Anisotropy"])

        process_folder(REAL_DIR, "Real", writer)
        process_folder(SYN_DIR, "Synthetic", writer)

    print(f"\n‚úÖ Exported all metrics to {csv_path}")


========== FILE: src/flow_simulation.py ==========

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import torch
import torch.nn.functional as F
from tqdm import tqdm
import pandas as pd

RESULTS_DIR = "results/flow_simulation"
os.makedirs(RESULTS_DIR, exist_ok=True)

# -------------------------------------------------------
# KEY CHANGE: porosity "ruler"
# Dark pixels = solid walls, light pixels = void/pores.
# With real images having mean ~0.73, we treat only the
# very bright pixels (> 0.80) as pores.
# -------------------------------------------------------
POROSITY_THRESHOLD = 0.80


def load_grayscale_images(path):
    if not os.path.exists(path):
        raise FileNotFoundError(f"üö´ Dataset folder not found: {path}")

    files = sorted(
        [f for f in os.listdir(path) if f.lower().endswith((".png", ".jpg", ".jpeg"))]
    )
    imgs = []
    shapes = set()
    for f in files:
        img = Image.open(os.path.join(path, f)).convert("L")
        arr = np.array(img, dtype=np.float32)
        shapes.add(arr.shape)

        # Normalize to [0,1]
        arr = (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)
        imgs.append(arr)

    if len(shapes) > 1:
        # Resize all to same shape (smallest H,W)
        target_h, target_w = min(s[0] for s in shapes), min(s[1] for s in shapes)
        resized_imgs = []
        for arr in imgs:
            arr = Image.fromarray((arr * 255).astype(np.uint8)).resize(
                (target_w, target_h), Image.BILINEAR
            )
            resized_imgs.append(np.array(arr, dtype=np.float32) / 255.0)
        imgs = resized_imgs

    return np.stack(imgs, axis=0)


def simulate_flow(img, steps=300, diffusivity=0.25):
    """
    Diffusion-based pseudo-flow simulation.

    Assumptions:
      - img is a 2D array in [0,1]
      - Dark pixels (near 0) = solid walls
      - Bright pixels (near 1) = pores / void
    """
    img_t = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
    h, w = img_t.shape[-2:]

    # Pressure initialized as uniform + small perturbation
    pressure = torch.rand_like(img_t) * 0.1

    # Diffusion mask (higher intensity = more flow)
    D = img_t * diffusivity

    for _ in range(steps):
        # 5-point Laplacian kernel
        lap = (
            F.pad(pressure, (0, 0, 1, 1))[..., 2:, :]
            + F.pad(pressure, (0, 0, 1, 1))[..., :-2, :]
            + F.pad(pressure, (1, 1, 0, 0))[..., :, 2:]
            + F.pad(pressure, (1, 1, 0, 0))[..., :, :-2]
            - 4 * pressure
        )
        pressure = pressure + D * lap

    # Compute gradient-based flow rate
    grad_y, grad_x = torch.gradient(pressure[0, 0])
    flow_rate = (grad_x.abs().mean() + grad_y.abs().mean()).item()

    # -------------------------------
    # Physics-ish summary metrics
    # -------------------------------
    mean_k = D.mean().item()
    mean_dpdy = grad_y.abs().mean().item()

    # KEY FIX: porosity uses POROSITY_THRESHOLD instead of 0.5
    # Only pixels brighter than 0.80 count as pores.
    porosity = (img > POROSITY_THRESHOLD).mean().item()

    anisotropy = float(
        grad_x.abs().mean() / (grad_y.abs().mean() + 1e-8)
    )

    return pressure.squeeze().numpy(), {
        "Mean_K": mean_k,
        "Mean_dP/dy": mean_dpdy,
        "FlowRate": flow_rate,
        "Porosity": porosity,
        "Anisotropy": anisotropy,
    }


def analyze_dataset_flow(name, path, tag):
    imgs = load_grayscale_images(path)
    metrics = []
    print(f"\nüåø Simulating flow for {name} structures...")
    for i, img in enumerate(tqdm(imgs, desc=name)):
        pressure_map, m = simulate_flow(img)
        m["Type"] = tag
        metrics.append(m)
        plt.imsave(
            os.path.join(RESULTS_DIR, f"flow_{name}_{i+1:03d}.png"),
            pressure_map,
            cmap="viridis",
        )

    df = pd.DataFrame(metrics)
    mean_eff = df["FlowRate"].mean()
    print(f"üåä Mean relative flow efficiency ({name}): {mean_eff:.4f}")
    return df, mean_eff


def main():
    real_df, real_eff = analyze_dataset_flow(
        "Real Xylem",
        "data/real_xylem_preprocessed",  # NEW: use grayscale preprocessed images
        "real",
    )
    synth_df, synth_eff = analyze_dataset_flow(
        "Synthetic Xylem", "data/generated_microtubes", "synthetic"
    )

    df_all = pd.concat([real_df, synth_df], ignore_index=True)
    os.makedirs("results/flow_metrics", exist_ok=True)
    df_all.to_csv("results/flow_metrics/flow_metrics.csv", index=False)
    print("\nüíæ Flow metrics saved ‚Üí results/flow_metrics/flow_metrics.csv")

    ratio = synth_eff / (real_eff + 1e-8)
    print(f"\nüß© Synthetic vs Real Flow Ratio: {ratio:.2f}")
    print(f"‚úÖ Flow simulation complete. Results in {RESULTS_DIR}")


if __name__ == "__main__":
    main()


========== FILE: src/flow_simulation_utils.py ==========

import numpy as np
import torch
import torch.nn.functional as F

# ==================================================
# üíß Compute Flow Physics Metrics
# ==================================================
def compute_flow_metrics(img, grad_scale=1.0):
    """
    Compute approximate flow physics metrics for a 2D xylem microstructure image.

    Args:
        img (np.ndarray): Grayscale image, either in [0, 1] or [0, 255].
        grad_scale (float): Optional multiplier to amplify flow sensitivity.

    Returns:
        dict with keys:
            - "K":         effective permeability proxy
            - "Porosity":  fraction of open (bright) pixels
            - "Anisotropy":ratio of |‚àÇx| to |‚àÇy|
    """
    ...
    # img is assumed to have been converted to a torch tensor called `tensor`
    # with shape [1, 1, H, W], and we already computed gx, gy, grad_mag above.

    # --------------------------------------------------
    # ‚úÖ FIXED POROSITY DEFINITION (Step #3)
    # --------------------------------------------------
    # We first make sure the image is in [0, 1]. If it‚Äôs still 0‚Äì255,
    # we normalize here. Then we apply a high threshold (0.80) so that
    # only very bright voxels count as ‚Äúvoid‚Äù / open space.
    max_val = float(tensor.max().item())
    if max_val > 1.5:
        # Likely 0‚Äì255 input ‚Üí normalize
        norm = tensor / 255.0
    else:
        # Already 0‚Äì1
        norm = tensor

    # Bright > 0.80 = void; rest = solid
    binary = (norm > 0.80).float()
    porosity = binary.mean().item()

    # Effective permeability proxy (inverse relation with gradient magnitude)
    K = (1.0 / (1.0 + grad_mag * (1 - porosity))).mean().item()

    # Directional anisotropy ratio (|‚àÇx| vs |‚àÇy|)
    anisotropy = (gx.abs().mean() / (gy.abs().mean() + 1e-8)).item()

    return {
        "K": K,
        "Porosity": porosity,
        "Anisotropy": anisotropy,
    }


========== FILE: src/generate_gradient_beam.py ==========

import torch
import numpy as np
import matplotlib.pyplot as plt
import os
from src.model import XylemAutoencoder

# CONFIG
MODEL_PATH = "results/model_physics_tuned.pth"
OUTPUT_DIR = "results/gradient_beam/"
BEAM_LENGTH_SLICES = 10
LATENT_DIM = 32

def interpolate_latents(model, n_steps=10):
    device = next(model.parameters()).device
    
    # 1. Generate random batch to find endpoints
    print("üîç Hunting for Dense and Porous endpoints...")
    z_batch = torch.randn(100, LATENT_DIM).to(device)
    with torch.no_grad():
        recon_batch = model.decode(z_batch)
    
    print(f"   Raw Output Range: [{recon_batch.min():.3f}, {recon_batch.max():.3f}]")
    
    # 2. Dynamic Normalization (The Fix)
    # Stretch the gray output (0.15-0.50) to full range (0.0-1.0)
    batch_min = recon_batch.min()
    batch_max = recon_batch.max()
    recon_norm = (recon_batch - batch_min) / (batch_max - batch_min + 1e-6)
    
    # 3. Relative Porosity
    # Any pixel in the top 50% brightness counts as a "void" for this metric
    porosities = (recon_norm > 0.5).float().mean(dim=[1, 2, 3])
    
    idx_dense = torch.argmin(porosities)
    idx_porous = torch.argmax(porosities)
    
    p_min = porosities[idx_dense].item()
    p_max = porosities[idx_porous].item()
    
    print(f"   Selected Dense: {p_min*100:.1f}% (Relative Porosity)")
    print(f"   Selected Porous: {p_max*100:.1f}% (Relative Porosity)")
    
    z_dense = z_batch[idx_dense]
    z_porous = z_batch[idx_porous]
    
    # 4. Interpolate
    alphas = np.linspace(0, 1, n_steps)
    z_steps = [((1 - a) * z_dense + a * z_porous) for a in alphas]
    return torch.stack(z_steps)

def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Robust Model Loading
    checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)
    model = XylemAutoencoder().to(device)
    if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
        model.load_state_dict(checkpoint['state_dict'])
    elif isinstance(checkpoint, dict):
        model.load_state_dict(checkpoint)
    else:
        model = checkpoint
    model.eval()
    
    # Generate Gradient
    z_gradient = interpolate_latents(model, n_steps=BEAM_LENGTH_SLICES)
    
    print("üåä Decoding gradient beam...")
    with torch.no_grad():
        beam_slices = model.decode(z_gradient)
        
    # --- VISUALIZATION PROCESSING ---
    beam_slices = beam_slices.cpu().numpy().squeeze()
    
    # 1. Stitch slices into one long beam
    full_beam = np.concatenate([s for s in beam_slices], axis=1)
    
    # 2. Normalize the entire beam for plotting (Stretch contrast to 0-1)
    full_beam_norm = (full_beam - full_beam.min()) / (full_beam.max() - full_beam.min() + 1e-6)
    
    # 3. Calculate Stiffness Profile
    # Inverted: Bright (1.0) is Void, Dark (0.0) is Solid
    # Density = 1.0 - Average Brightness
    beam_density_profile = 1.0 - np.mean(full_beam_norm, axis=0)
    
    # Stiffness Heuristic: E ~ Density^2
    beam_stiffness_profile = beam_density_profile ** 2
    
    # --- PLOTTING ---
    fig, axes = plt.subplots(2, 1, figsize=(15, 8), gridspec_kw={'height_ratios': [1, 2]})
    
    # Top Plot: Stiffness Curve
    axes[0].plot(beam_stiffness_profile, color='#d62728', linewidth=3)
    axes[0].set_title("Predicted Stiffness Gradient ($E \\propto \\rho^2$)", fontsize=16, fontweight='bold')
    axes[0].set_ylabel("Stiffness Potential", fontsize=12)
    axes[0].set_xlabel("Longitudinal Position", fontsize=10)
    axes[0].grid(True, alpha=0.3, linestyle='--')
    
    # Bottom Plot: The Gradient Structure
    # Use 'gray_r' so dense material looks black/dark
    axes[1].imshow(full_beam_norm, cmap='gray_r', aspect='auto')
    axes[1].set_title(f"Generative Functionally Graded Beam ({BEAM_LENGTH_SLICES} Segments)", fontsize=14)
    axes[1].axis('off')
    
    plt.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, "gradient_beam_analysis.png")
    plt.savefig(save_path, dpi=150)
    print(f"‚úÖ Gradient analysis saved to {save_path}")

if __name__ == "__main__":
    main()

========== FILE: src/generate_structures.py ==========

import os
import argparse
import numpy as np
from PIL import Image
import torch
from torch import nn
from src.model import XylemAutoencoder
import pandas as pd


def save_image_from_tensor(tensor, path):
    """
    Save a single-channel tensor [1,H,W] or [H,W] as a grayscale PNG using PIL.
    Assumes values are in [0, 1].
    """
    if tensor.ndim == 3:
        tensor = tensor.squeeze(0)  # [1,H,W] -> [H,W]
    arr = tensor.detach().cpu().numpy()
    arr = np.clip(arr * 255.0, 0, 255).astype(np.uint8)
    img = Image.fromarray(arr, mode="L")
    img.save(path)


def generate_structures(model_path, n=64, out_dir="data/generated_microtubes"):
    """
    Load a tuned autoencoder model and generate N synthetic microtubes
    by sampling latent vectors from a standard normal distribution,
    decoding them to images, and saving them as PNGs.
    Also logs latent vectors for analysis.
    """
    device = torch.device("cpu")

    # Load model
    model = XylemAutoencoder()
    state_dict = torch.load(model_path, map_location=device)
    model.load_state_dict(state_dict)
    model.to(device)
    model.eval()

    os.makedirs(out_dir, exist_ok=True)

    # Latent dimension inferred from model
    latent_dim = model.latent_dim if hasattr(model, "latent_dim") else 32

    generated = []
    with torch.no_grad():
        for i in range(n):
            # Sample a random latent code
            z = torch.randn(1, latent_dim, device=device)

            # Decode to image
            recon = model.decode(z)  # [1,1,256,256]
            img_tensor = recon[0, 0]  # [H,W]

            # Save to disk
            filename = f"synthetic_{i:03d}.png"
            filepath = os.path.join(out_dir, filename)
            save_image_from_tensor(img_tensor, filepath)

            generated.append({
                "filename": filename,
                "z": z.detach().cpu().numpy().flatten().tolist()
            })

    # Save latent log as CSV/JSON-ish
    log_path = os.path.join(out_dir, "generation_log.csv")
    pd.DataFrame(generated).to_csv(log_path, index=False)
    print(f"‚úÖ Generated {n} structures in {out_dir}")
    print(f"üßæ Generation log saved ‚Üí {log_path}")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, required=True, help="Path to tuned model (.pth)")
    parser.add_argument("--n", type=int, default=64, help="Number of structures to generate")
    args = parser.parse_args()

    generate_structures(args.model, args.n)


if __name__ == "__main__":
    main()

========== FILE: src/heat_simulation.py ==========

"""
heat_simulation.py ‚Äî 2D steady-state heat solver for "thermal sponge" designs.

Given binary-ish microstructure images (solid vs void), we:
  - Map them to a conductivity field k(x,y)
  - Solve ‚àá¬∑(k ‚àáT) = 0 with simple Dirichlet BCs:
      * Left boundary: hot chip  (T = T_HOT)
      * Right boundary: cold sink (T = T_COLD)
      * Top/bottom: insulated (Neumann ‚âà no-flux)
  - Compute:
      * T_max_chip: max temperature in a hot-strip near the left side
      * Q_total: total heat flux leaving at the cold boundary
      * rho_solid: solid volume fraction (material cost)
  - Save metrics for all images to results/thermal_metrics/thermal_metrics.csv
"""

import os
import numpy as np
import pandas as pd
from PIL import Image

# ------------------------
# Config
# ------------------------
DATA_DIR = "data/generated_microtubes"
OUTPUT_DIR = "results/thermal_metrics"  # Ensure directory exists
OUTPUT_CSV = os.path.join(OUTPUT_DIR, "thermal_metrics.csv")

IMG_EXTS = (".png", ".jpg", ".jpeg", ".tif")

# Image ‚Üí material mapping
# Adjusted threshold for Robust Normalized images:
# After normalization, 0.5 is the median gray. 
# Anything brighter than 0.6 is VOID (Water/Air). Darker is SOLID (Metal).
VOID_THRESHOLD = 0.60   
K_SOLID = 1.0           # relative conductivity of solid (Metal)
K_VOID = 0.05           # relative conductivity of void (Water/Air)

# Thermal BCs
T_HOT = 1.0
T_COLD = 0.0
HOT_STRIP_WIDTH = 5      # how many columns from the left we treat as "chip" region for T_max

# Solver
MAX_ITERS = 4000
TOL = 1e-4              # residual stopping criterion
PRINT_EVERY = 500       # how often to print residual


# ------------------------
# Core solver
# ------------------------
def solve_steady_heat(k_grid, t_hot=T_HOT, t_cold=T_COLD,
                      max_iters=MAX_ITERS, tol=TOL, print_every=PRINT_EVERY):
    """
    Solve ‚àá¬∑(k ‚àáT) = 0 on a 2D grid with:
      - Left boundary: T = t_hot
      - Right boundary: T = t_cold
      - Top/bottom: insulated (approx via copying interior values)

    k_grid: (H, W) conductivity field.
    Returns: T (H, W), steady-state temperature field.
    """
    H, W = k_grid.shape
    T = np.zeros((H, W), dtype=np.float32)
    
    # Linear Initialization (Speeds up convergence vs Zeros)
    x_coords = np.linspace(t_hot, t_cold, W)
    T[:] = x_coords  
    
    T[:, 0] = t_hot
    T[:, -1] = t_cold

    # Convenience for boundary masks
    left_idx = 0
    right_idx = W - 1

    for it in range(max_iters):
        max_delta = 0.0

        # Neumann on top/bottom: copy neighbors (simple approximation)
        # This keeps dT/dn ‚âà 0 at boundaries
        T[0, :] = T[1, :]
        T[-1, :] = T[-2, :]

        # Gauss‚ÄìSeidel update on interior (excluding left/right Dirichlet cols)
        # Vectorized implementation (much faster than loops)
        # Note: This is a Jacobi update (parallel), but works for convergence.
        # T_new = (k_n*T_up + k_s*T_down + k_w*T_left + k_e*T_right) / sum_k
        
        # Shifted arrays for neighbors
        T_up    = T[0:-2, 1:-1]
        T_down  = T[2:,   1:-1]
        T_left  = T[1:-1, 0:-2]
        T_right = T[1:-1, 2:]
        
        # Current K
        k_c = k_grid[1:-1, 1:-1]
        
        # Neighbor K (Harmonic Mean for interface conductivity)
        # Harmonic mean handles the sharp jump from k=1 to k=0.05 better than arithmetic
        eps = 1e-8
        k_n = 2 * k_c * k_grid[0:-2, 1:-1] / (k_c + k_grid[0:-2, 1:-1] + eps)
        k_s = 2 * k_c * k_grid[2:,   1:-1] / (k_c + k_grid[2:,   1:-1] + eps)
        k_w = 2 * k_c * k_grid[1:-1, 0:-2] / (k_c + k_grid[1:-1, 0:-2] + eps)
        k_e = 2 * k_c * k_grid[1:-1, 2:]   / (k_c + k_grid[1:-1, 2:]   + eps)
        
        denom = k_n + k_s + k_w + k_e + eps
        
        T_new_interior = (k_n * T_up + k_s * T_down + k_w * T_left + k_e * T_right) / denom
        
        # Calculate Delta
        delta = np.abs(T_new_interior - T[1:-1, 1:-1])
        current_max_delta = np.max(delta)
        
        # Update T
        T[1:-1, 1:-1] = T_new_interior
        
        if (it + 1) % print_every == 0:
            print(f"   [heat] iter {it+1:4d}/{max_iters}, max ŒîT = {current_max_delta:.3e}")
        
        if current_max_delta < tol:
            break

    return T


def compute_metrics(img_arr, T, k_grid):
    """
    img_arr: (H, W) in [0,1]
    T:       (H, W) temperature field
    k_grid:  (H, W) conductivity field

    Returns:
      T_max_chip, Q_total, rho_solid
    """
    H, W = img_arr.shape

    # Solid vs void (consistent with VOID_THRESHOLD convention)
    # Bright pixels (> Threshold) are Void. Dark pixels are Solid.
    solid_mask = img_arr <= VOID_THRESHOLD
    rho_solid = solid_mask.mean()

    # Chip / hot strip region (left HOT_STRIP_WIDTH columns)
    chip_cols = min(HOT_STRIP_WIDTH, W)
    chip_region = T[:, :chip_cols]
    T_max_chip = float(chip_region.max())

    # Heat flux through cold boundary (right boundary)
    # Approximate q = -k * dT/dx, so:
    #   dT/dx ‚âà T[:, -1] - T[:, -2]
    #   Note: T[:,-1] is 0.0 (Cold Sink). T[:,-2] is > 0.
    #   So dT/dx is negative. Flux should be positive leaving the domain?
    #   Fourier Law: q = -k dT/dx.
    #   Flux vector points Right.
    dTdx = T[:, -1] - T[:, -2] # (0 - Positive) = Negative
    q_boundary = -k_grid[:, -1] * dTdx # (-k * Negative) = Positive Flux
    Q_total = float(q_boundary.sum())

    return T_max_chip, Q_total, float(rho_solid)


# ------------------------
# Main loop over images
# ------------------------
def main():
    if not os.path.exists(DATA_DIR):
        raise FileNotFoundError(f"Input directory not found: {DATA_DIR}")

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    files = sorted(f for f in os.listdir(DATA_DIR)
                   if f.lower().endswith(IMG_EXTS))

    if not files:
        raise RuntimeError(f"No images found in {DATA_DIR} with extensions {IMG_EXTS}")

    print(f"üå°Ô∏è  Running thermal simulation on {len(files)} structures...")
    print(f"   Data dir: {DATA_DIR}")
    print(f"   Output:   {OUTPUT_CSV}")
    print(f"   Void threshold: {VOID_THRESHOLD}, K_solid={K_SOLID}, K_void={K_VOID}")

    records = []

    for idx, fname in enumerate(files, start=1):
        path = os.path.join(DATA_DIR, fname)
        img = Image.open(path).convert("L")
        arr_raw = np.array(img, dtype=np.float32)
        
        # --- ROBUST NORMALIZATION FIX ---
        # Stretch contrast to full 0.0-1.0 range so gray images become B/W
        img_min, img_max = arr_raw.min(), arr_raw.max()
        if img_max > img_min:
            arr_norm = (arr_raw - img_min) / (img_max - img_min)
        else:
            arr_norm = arr_raw / 255.0 # Fallback for blank images
            
        # Map to conductivity field
        # White (>= threshold) = void (low k), dark = solid (high k)
        void_mask = arr_norm > VOID_THRESHOLD
        solid_mask = ~void_mask
        k_grid = np.where(solid_mask, K_SOLID, K_VOID).astype(np.float32)

        print(f"\n[{idx}/{len(files)}] {fname}")
        T = solve_steady_heat(k_grid)

        T_max_chip, Q_total, rho_solid = compute_metrics(arr_norm, T, k_grid)

        print(f"   ‚ûú T_max_chip = {T_max_chip:.4f}, "
              f"Q_total = {Q_total:.4e}, "
              f"rho_solid = {rho_solid:.3f}")

        records.append({
            "filename": fname,
            "T_max_chip": T_max_chip,
            "Q_total": Q_total,
            "rho_solid": rho_solid,
        })

    df = pd.DataFrame(records)
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"\n‚úÖ Thermal metrics saved ‚Üí {OUTPUT_CSV}")


if __name__ == "__main__":
    main()

========== FILE: src/latent_validation_real_vs_synthetic.py ==========

"""
latent_validation_real_vs_synthetic.py
Compare latent space distributions between real and synthetic xylem structures.
"""

import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from PIL import Image
from torchvision import transforms
from src.model import XylemAutoencoder

# -------------------------------
# Configuration
# -------------------------------
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_PATH = "results/model.pth"
REAL_DIR = "data/real_xylem_preprocessed"
SYN_DIR = "data/generated_microtubes"
SAVE_PATH = "results/latent_validation"
os.makedirs(SAVE_PATH, exist_ok=True)

# -------------------------------
# Load model
# -------------------------------
print("‚öôÔ∏è Loading model...")
model = XylemAutoencoder(latent_dim=32).to(DEVICE)
checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)

# Partial load with mismatched keys skipped
model_dict = model.state_dict()
compatible_dict = {k: v for k, v in checkpoint.items() if k in model_dict and v.shape == model_dict[k].shape}
model_dict.update(compatible_dict)
model.load_state_dict(model_dict)
print(f"‚úÖ Loaded {len(compatible_dict)} compatible layers.")

# -------------------------------
# Image preprocessing
# -------------------------------
transform = transforms.Compose([
    transforms.Grayscale(),
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

def load_images(path, n=None):
    imgs = []
    valid_ext = (".png", ".jpg", ".jpeg", ".tif", ".tiff")
    for f in sorted(os.listdir(path)):
        full_path = os.path.join(path, f)
        if not os.path.isfile(full_path) or not f.lower().endswith(valid_ext):
            continue
        img = Image.open(full_path).convert("L")
        imgs.append(transform(img).unsqueeze(0))
        if n and len(imgs) >= n:
            break
    return torch.cat(imgs, dim=0)

# -------------------------------
# Load datasets
# -------------------------------
print("üì• Loading datasets...")
real_imgs = load_images(REAL_DIR)
syn_imgs = load_images(SYN_DIR)
real_imgs, syn_imgs = real_imgs.to(DEVICE), syn_imgs.to(DEVICE)

# -------------------------------
# Encode latent space
# -------------------------------
print("üî¨ Encoding latent representations...")
with torch.no_grad():
    z_real, _ = model(real_imgs)
    z_syn, _ = model(syn_imgs)

# Flatten latent tensors for PCA
z_real = z_real.view(z_real.size(0), -1).cpu().numpy()
z_syn = z_syn.view(z_syn.size(0), -1).cpu().numpy()

# -------------------------------
# Dimensionality reduction
# -------------------------------
print("üìâ Projecting to 2D space (PCA + t-SNE)...")
all_z = np.concatenate([z_real, z_syn], axis=0)
labels = np.array(["Real"] * len(z_real) + ["Synthetic"] * len(z_syn))

pca = PCA(n_components=min(20, all_z.shape[1])).fit_transform(all_z)

tsne = TSNE(
    n_components=2,
    perplexity=5,
    max_iter=2000,
    learning_rate="auto",
    init="pca",
    random_state=42
).fit_transform(pca)

# -------------------------------
# Plot latent overlap
# -------------------------------
print("üß© Plotting latent overlap map...")
plt.figure(figsize=(8, 6))
plt.scatter(tsne[labels == "Real", 0], tsne[labels == "Real", 1],
            alpha=0.6, label="Real Xylem", s=50)
plt.scatter(tsne[labels == "Synthetic", 0], tsne[labels == "Synthetic", 1],
            alpha=0.6, label="Synthetic Xylem", s=50)
plt.legend()
plt.title("Latent Space Overlap: Real vs Synthetic Xylem Structures")
plt.xlabel("t-SNE Dim 1")
plt.ylabel("t-SNE Dim 2")

save_file = os.path.join(SAVE_PATH, "latent_overlap.png")
plt.savefig(save_file, dpi=300)
plt.close()

print(f"‚úÖ Latent validation complete! Saved visualization to {save_file}")


========== FILE: src/map_latent_to_physics.py ==========

"""
map_latent_to_physics.py
Visualize how learned latent representations correlate with physical performance metrics.
"""

import os, sys, subprocess, numpy as np, torch, matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler

# dependency check
REQUIRED = ["torch", "matplotlib", "numpy", "scikit-learn", "Pillow"]
for pkg in REQUIRED:
    try:
        __import__(pkg)
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install", pkg])

# paths
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(CURRENT_DIR)
RESULTS_DIR = os.path.join(ROOT_DIR, "results", "latent_physics_map")
os.makedirs(RESULTS_DIR, exist_ok=True)

# import model + physics
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)
from src.model import XylemAutoencoder
from src.simulate_flow import simulate_pressure_field, compute_conductivity

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
LATENT_DIM = 32
SAMPLES = 50

# --- main ---
def main():
    model = XylemAutoencoder(latent_dim=LATENT_DIM).to(DEVICE)
    dummy = torch.zeros(1,1,256,256).to(DEVICE); _ = model(dummy)
    state_dict = torch.load(os.path.join(ROOT_DIR, "results", "xylem_autoencoder.pt"), map_location=DEVICE)
    model.load_state_dict(state_dict, strict=False)
    model.eval()

    zs, conductivities = [], []

    for _ in range(SAMPLES):
        z = torch.randn(1, LATENT_DIM, device=DEVICE)
        recon = model.decoder_deconv(model.fc_dec(z).view(-1,128,16,16))
        img = recon.detach().cpu().numpy()[0,0]
        p_field, mask = simulate_pressure_field(img)
        cond = compute_conductivity(p_field, mask)
        zs.append(z.cpu().numpy().flatten())
        conductivities.append(cond)

    Z = np.array(zs)
    conductivities = np.array(conductivities)
    Z_scaled = StandardScaler().fit_transform(Z)

    # dimensionality reduction
    emb = TSNE(n_components=2, perplexity=15, learning_rate="auto", init="random").fit_transform(Z_scaled)

    # visualization
    plt.figure(figsize=(6,5))
    sc = plt.scatter(emb[:,0], emb[:,1], c=conductivities, cmap="viridis", s=60, alpha=0.8)
    plt.colorbar(sc, label="Conductivity")
    plt.title("Latent Space vs Physical Conductivity")
    plt.xlabel("Latent dim 1")
    plt.ylabel("Latent dim 2")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(RESULTS_DIR, "latent_physics_map.png"), dpi=200)
    plt.close()

    print("‚úÖ Latent-Physics mapping complete.")
    print(f"Results saved to {RESULTS_DIR}")

if __name__ == "__main__":
    main()


========== FILE: src/model.py ==========

"""
model.py
----------------------------------------
Defines the XylemAutoencoder architecture used for
synthetic tree vascular structure encoding and reconstruction.

This model learns a compact latent representation ("genetic code")
for microvascular patterns, which can be decoded into
2D images and analyzed through the physics simulator.
"""

import torch
from torch import nn
import torch.nn.functional as F


class XylemAutoencoder(nn.Module):
    def __init__(self, latent_dim=32):
        super(XylemAutoencoder, self).__init__()
        self.latent_dim = latent_dim

        # ==========================
        # Encoder ‚Äî compress geometry
        # ==========================
        self.encoder_conv = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # 256 ‚Üí 128
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 128 ‚Üí 64
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # 64 ‚Üí 32
            nn.ReLU(inplace=True),
        )

        # Flatten to latent vector
        self.fc_enc = nn.Linear(128 * 32 * 32, latent_dim)

        # ==========================
        # Decoder ‚Äî reconstruct geometry
        # ==========================
        self.fc_dec = nn.Linear(latent_dim, 128 * 16 * 16)
        self.decoder_conv = nn.Sequential(
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 16 ‚Üí 32
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),   # 32 ‚Üí 64
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),   # 64 ‚Üí 128
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=1),    # 128 ‚Üí 256
            nn.Sigmoid()
        )

    def encode(self, x):
        """Encodes input structure ‚Üí latent vector."""
        x = self.encoder_conv(x)
        x = x.view(x.size(0), -1)
        z = self.fc_enc(x)
        return z

    def decode(self, z):
        """Decodes latent vector ‚Üí reconstructed structure."""
        x = self.fc_dec(z)
        x = x.view(-1, 128, 16, 16)
        x = self.decoder_conv(x)
        return x

    def forward(self, x):
        """Full forward pass: encode ‚Üí decode."""
        z = self.encode(x)
        recon = self.decode(z)
        return recon, z


# ===============================================================
# Optional quick test to verify correct output shape
# ===============================================================
if __name__ == "__main__":
    model = XylemAutoencoder(latent_dim=32)
    dummy = torch.randn(1, 1, 256, 256)
    recon, z = model(dummy)
    print(f"‚úÖ Model forward test successful.")
    print(f"Input shape: {dummy.shape}")
    print(f"Latent shape: {z.shape}")
    print(f"Reconstruction shape: {recon.shape}")

========== FILE: src/morpho_analysis.py ==========

"""
morpho_analysis.py
----------------------------------------
Analyzes and visualizes the evolution of vascular structures
generated by the Synthetic Cambium Growth Loop.

Outputs:
1. Conductivity improvement curve
2. Morphological timeline (image grid)
3. Optional latent drift visualization (if latent data available)
"""

import os, numpy as np, matplotlib.pyplot as plt
from PIL import Image

# --- Config ---
RESULTS_DIR = os.path.join("results", "cambium_growth")
SAVE_DIR = os.path.join("results", "morpho_analysis")
os.makedirs(SAVE_DIR, exist_ok=True)

# ===============================================================
# 1Ô∏è‚É£ Conductivity curve
# ===============================================================

def plot_conductivity_curve():
    path = os.path.join(RESULTS_DIR, "conductivity_history.txt")
    if not os.path.exists(path):
        raise FileNotFoundError("Conductivity history not found. Run synthetic_cambium.py first.")
    
    data = np.loadtxt(path)
    plt.figure(figsize=(6,4))
    plt.plot(data, color="black", lw=2)
    plt.title("Conductivity Improvement Over Growth Iterations")
    plt.xlabel("Iteration")
    plt.ylabel("Effective Conductivity")
    plt.grid(alpha=0.3)
    plt.tight_layout()
    savepath = os.path.join(SAVE_DIR, "conductivity_curve.png")
    plt.savefig(savepath, dpi=300)
    plt.close()
    print(f"‚úÖ Conductivity curve saved to {savepath}")
    return savepath


# ===============================================================
# 2Ô∏è‚É£ Morphological timeline
# ===============================================================

def create_morphology_timeline(max_images=10):
    """
    Creates a horizontal strip showing morphology changes across iterations.
    """
    imgs = sorted([f for f in os.listdir(RESULTS_DIR) if f.startswith("growth_") and f.endswith(".png")])
    imgs = imgs[:max_images]
    if not imgs:
        raise FileNotFoundError("No growth images found in results/cambium_growth")

    images = [Image.open(os.path.join(RESULTS_DIR, f)).convert("L") for f in imgs]
    widths, heights = zip(*(img.size for img in images))
    total_width = sum(widths)
    max_height = max(heights)

    timeline = Image.new("L", (total_width, max_height))
    x_offset = 0
    for img in images:
        timeline.paste(img, (x_offset, 0))
        x_offset += img.size[0]

    savepath = os.path.join(SAVE_DIR, "morphology_timeline.png")
    timeline.save(savepath)
    print(f"‚úÖ Morphological timeline saved to {savepath}")
    return savepath


# ===============================================================
# 3Ô∏è‚É£ Optional: Latent drift visualization (if latent.npy exists)
# ===============================================================

def plot_latent_drift(latent_path="results/latent_history.npy"):
    """
    Projects latent evolution in 2D if recorded.
    """
    if not os.path.exists(latent_path):
        print("‚ÑπÔ∏è No latent history found. Skipping latent drift visualization.")
        return None
    
    try:
        from umap import UMAP
    except ImportError:
        print("‚ö†Ô∏è UMAP not installed. Run `pip install umap-learn` to enable latent drift plotting.")
        return None

    z_hist = np.load(latent_path)
    reducer = UMAP(n_neighbors=5, min_dist=0.2, random_state=42)
    proj = reducer.fit_transform(z_hist)

    plt.figure(figsize=(5,5))
    plt.scatter(proj[:,0], proj[:,1], c=np.arange(len(proj)), cmap="viridis", s=20)
    plt.colorbar(label="Iteration")
    plt.title("Latent Drift During Growth")
    plt.tight_layout()
    savepath = os.path.join(SAVE_DIR, "latent_drift.png")
    plt.savefig(savepath, dpi=300)
    plt.close()
    print(f"‚úÖ Latent drift plot saved to {savepath}")
    return savepath


# ===============================================================
# Main
# ===============================================================

def main():
    print("üìä Running Morphological Analytics...")
    curve = plot_conductivity_curve()
    timeline = create_morphology_timeline()
    drift = plot_latent_drift()

    print("\n‚úÖ Morphological analysis complete.")
    print(f" - Conductivity curve: {curve}")
    print(f" - Morphology timeline: {timeline}")
    if drift: print(f" - Latent drift plot: {drift}")


if __name__ == "__main__":
    main()


========== FILE: src/morphological_convergence_curve.py ==========

"""
morphological_convergence_curve.py
-------------------------------------
Visualizes morphological convergence metrics (latent distance, overlap, SSIM)
across training epochs, with smoothing and confidence shading.
"""

import os
import json
import numpy as np
import matplotlib.pyplot as plt

HISTORY_PATH = "results/morphology_metrics/history.json"
SAVE_PATH = "results/morphology_metrics/morphological_convergence_curve.png"

def ema_smooth(values, alpha=0.5):
    """Exponential moving average smoothing."""
    smoothed = []
    s = values[0]
    for v in values:
        s = alpha * v + (1 - alpha) * s
        smoothed.append(s)
    return np.array(smoothed)

if not os.path.exists(HISTORY_PATH):
    print("‚ö†Ô∏è No history.json found ‚Äî run morphology_metrics.py first.")
    exit()

with open(HISTORY_PATH, "r") as f:
    history = json.load(f)

epochs = np.arange(1, len(history["latent_distance"]) + 1)

plt.figure(figsize=(8, 5))
plt.title("Morphological Convergence Across Training Epochs", fontsize=14)

colors = {
    "latent_distance": "#2ca02c",
    "cluster_overlap": "#1f77b4",
    "ssim": "#d62728"
}

for key, label in [
    ("latent_distance", "Latent Distance ‚Üì"),
    ("cluster_overlap", "Cluster Overlap ‚Üë"),
    ("ssim", "SSIM ‚Üë")
]:
    y = np.array(history[key])
    y_smooth = ema_smooth(y, alpha=0.4)
    plt.plot(epochs, y_smooth, label=label, color=colors[key], linewidth=2)
    plt.fill_between(epochs, y_smooth * 0.95, y_smooth * 1.05, color=colors[key], alpha=0.15)

plt.xlabel("Epochs / Retraining Cycle", fontsize=12)
plt.ylabel("Normalized Metric Value", fontsize=12)
plt.grid(True, linestyle="--", alpha=0.5)
plt.legend(frameon=False)
plt.tight_layout()

plt.savefig(SAVE_PATH, dpi=300, bbox_inches="tight")
plt.close()
print(f"‚úÖ Saved smoothed convergence plot ‚Üí {SAVE_PATH}")


========== FILE: src/morphology_dashboard.py ==========

"""
morphology_dashboard.py
-------------------------------------
Creates a summary dashboard comparing
Pre- vs Post-Hybrid morphological convergence.
"""

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import json
import os

# Paths
PRE_PATH = "results/morphology_metrics/latent_overlap_Pre-Hybrid.png"
POST_PATH = "results/morphology_metrics/latent_overlap_Post-Hybrid.png"
METRICS_PATH = "results/morphology_metrics/metrics_summary.json"
SAVE_PATH = "results/morphology_metrics/morphology_dashboard.png"

# Load images
img_pre = mpimg.imread(PRE_PATH)
img_post = mpimg.imread(POST_PATH)

# Load metrics (optional)
metrics = {}
if os.path.exists(METRICS_PATH):
    with open(METRICS_PATH, "r") as f:
        metrics = json.load(f)

# Build figure
fig, axes = plt.subplots(1, 3, figsize=(14, 5))

# Pre-hybrid map
axes[0].imshow(img_pre)
axes[0].axis("off")
axes[0].set_title("Latent Space: Pre-Hybrid")

# Post-hybrid map
axes[1].imshow(img_post)
axes[1].axis("off")
axes[1].set_title("Latent Space: Post-Hybrid")

# Metrics bar chart (if available)
if metrics:
    labels = list(metrics.keys())
    pre_vals = [metrics[k]["pre"] for k in labels]
    post_vals = [metrics[k]["post"] for k in labels]

    axes[2].barh(labels, pre_vals, color="gray", alpha=0.6, label="Pre")
    axes[2].barh(labels, post_vals, color="green", alpha=0.6, label="Post")
    axes[2].invert_yaxis()
    axes[2].set_title("Morphological Metrics")
    axes[2].legend()
else:
    axes[2].text(0.5, 0.5, "No metrics JSON found", ha="center", va="center")
    axes[2].axis("off")

plt.tight_layout()
plt.savefig(SAVE_PATH, dpi=300)
plt.close()

print(f"‚úÖ Dashboard saved to {SAVE_PATH}")


========== FILE: src/morphology_metrics.py ==========

"""
morphology_metrics.py
-------------------------------------
Quantifies morphological similarity between:
  - Real xylem images (UruDendro dataset)
  - Synthetic microtube structures
  - Post-hybrid model reconstructions

Outputs latent distance, SSIM, and cluster overlap indices.
Now logs history across runs for morphological convergence visualization.
"""

import os
import json
import numpy as np
import torch
import torch.nn.functional as F
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image
from src.model import XylemAutoencoder
from sklearn.metrics import pairwise_distances
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from skimage.metrics import structural_similarity as ssim
import matplotlib.pyplot as plt

# ---------------------------------------
# CONFIG
# ---------------------------------------
REAL_DIR = "data/real_xylem_preprocessed"
SYN_DIR = "data/generated_microtubes"
MODEL_PATH_BASE = "results/model.pth"
MODEL_PATH_HYBRID = "results/hybrid_training/model_hybrid.pth"
SAVE_DIR = "results/morphology_metrics"
os.makedirs(SAVE_DIR, exist_ok=True)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
BATCH_SIZE = 4
LATENT_DIM = 32

# ---------------------------------------
# DATASET
# ---------------------------------------
class XylemDataset(Dataset):
    def __init__(self, path, transform=None):
        self.files = [os.path.join(path, f) for f in os.listdir(path)
                      if f.lower().endswith((".png", ".jpg", ".jpeg"))]
        self.transform = transform

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        img = Image.open(self.files[idx]).convert("L")
        if self.transform:
            img = self.transform(img)
        return img

transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# ---------------------------------------
# UTILITIES
# ---------------------------------------
def extract_latents(model, dataloader):
    model.eval()
    latents, recons, imgs = [], [], []
    with torch.no_grad():
        for batch in dataloader:
            batch = batch.to(DEVICE)
            recon, z = model(batch)
            latents.append(z.cpu().numpy())
            recons.append(recon.cpu().numpy())
            imgs.append(batch.cpu().numpy())
    return np.concatenate(latents), np.concatenate(recons), np.concatenate(imgs)

def latent_distance(z_real, z_syn):
    """Compute mean latent L2 distance between real and synthetic embeddings."""
    dist = pairwise_distances(z_real, z_syn, metric="euclidean")
    return np.mean(dist)

def cluster_overlap_index(z_real, z_syn):
    """Rough cluster overlap using t-SNE and centroid distance ratio."""
    pca = PCA(n_components=10).fit_transform(np.concatenate([z_real, z_syn]))
    tsne = TSNE(n_components=2, perplexity=10, learning_rate="auto").fit_transform(pca)
    real_pts, syn_pts = tsne[:len(z_real)], tsne[len(z_real):]
    centroid_dist = np.linalg.norm(real_pts.mean(0) - syn_pts.mean(0))
    cluster_spread = np.std(tsne, axis=0).mean()
    return 1 - min(1.0, centroid_dist / (2 * cluster_spread))

def compute_ssim(real_recon, syn_recon):
    """Compute structural similarity index between average reconstructions."""
    real_mean = np.mean(real_recon, axis=0).squeeze()
    syn_mean = np.mean(syn_recon, axis=0).squeeze()
    return ssim(real_mean, syn_mean, data_range=1.0)

# ---------------------------------------
# JSON SAVE FUNCTION
# ---------------------------------------
def save_metrics_to_json(metrics_base, metrics_hybrid, save_dir=SAVE_DIR):
    summary = {}
    for key in metrics_base:
        summary[key] = {
            "pre": float(metrics_base[key]),
            "post": float(metrics_hybrid[key]),
            "improvement_%": float(
                ((metrics_base[key] - metrics_hybrid[key]) / metrics_base[key]) * 100
            ) if metrics_base[key] != 0 else 0
        }

    json_path = os.path.join(save_dir, "metrics_summary.json")
    with open(json_path, "w") as f:
        json.dump(summary, f, indent=4)
    print(f"üíæ Saved metrics JSON to {json_path}")

# ---------------------------------------
# MAIN
# ---------------------------------------
def analyze_model(model_path, label):
    print(f"üß† Evaluating model: {label}")
    model = XylemAutoencoder(latent_dim=LATENT_DIM).to(DEVICE)
    checkpoint = torch.load(model_path, map_location=DEVICE)
    model_dict = model.state_dict()
    compat = {k: v for k, v in checkpoint.items() if k in model_dict and v.shape == model_dict[k].shape}
    model_dict.update(compat)
    model.load_state_dict(model_dict)
    print(f"‚úÖ Loaded {len(compat)} layers from {model_path}")

    # Load data
    real_loader = DataLoader(XylemDataset(REAL_DIR, transform), batch_size=BATCH_SIZE)
    syn_loader = DataLoader(XylemDataset(SYN_DIR, transform), batch_size=BATCH_SIZE)

    z_real, recon_real, imgs_real = extract_latents(model, real_loader)
    z_syn, recon_syn, imgs_syn = extract_latents(model, syn_loader)

    metrics = {
        "latent_distance": latent_distance(z_real, z_syn),
        "cluster_overlap": cluster_overlap_index(z_real, z_syn),
        "ssim": compute_ssim(recon_real, recon_syn)
    }

    print(f"\nüìä {label} Morphology Metrics:")
    print("-" * 50)
    for k, v in metrics.items():
        print(f"{k:20s}: {v:.4f}")
    print()

    # Save t-SNE plot
    pca = PCA(n_components=10).fit_transform(np.concatenate([z_real, z_syn]))
    tsne = TSNE(n_components=2, perplexity=10, learning_rate="auto").fit_transform(pca)
    plt.figure(figsize=(6, 5))
    plt.scatter(tsne[:len(z_real), 0], tsne[:len(z_real), 1], label="Real", alpha=0.7)
    plt.scatter(tsne[len(z_real):, 0], tsne[len(z_real):, 1], label="Synthetic", alpha=0.7)
    plt.title(f"Latent Overlap ({label})")
    plt.legend()
    plot_path = os.path.join(SAVE_DIR, f"latent_overlap_{label}.png")
    plt.savefig(plot_path, dpi=200, bbox_inches="tight")
    plt.close()
    print(f"üìà Saved plot: {plot_path}")

    # ---------------------------------------
    # üß© Log metrics history for convergence tracking
    # ---------------------------------------
    history_path = os.path.join(SAVE_DIR, "history.json")
    if not os.path.exists(history_path):
        history = {"latent_distance": [], "cluster_overlap": [], "ssim": []}
    else:
        with open(history_path, "r") as f:
            history = json.load(f)

    for key in metrics:
        history[key].append(float(metrics[key]))

    with open(history_path, "w") as f:
        json.dump(history, f, indent=4)
    print(f"üßæ Updated history log ‚Üí {history_path}")

    return metrics

# ---------------------------------------
# RUN
# ---------------------------------------
if __name__ == "__main__":
    metrics_base = analyze_model(MODEL_PATH_BASE, "Pre-Hybrid")
    metrics_hybrid = analyze_model(MODEL_PATH_HYBRID, "Post-Hybrid")

    print("\nüî¨ Morphological Convergence Summary")
    print("=" * 50)
    for key in metrics_base:
        base, hybrid = metrics_base[key], metrics_hybrid[key]
        delta = ((base - hybrid) / base) * 100 if base != 0 else 0
        trend = "‚Üë improved" if hybrid < base else "‚Üì worse" if hybrid > base else "‚Äì no change"
        print(f"{key:20s}: {base:.4f} ‚Üí {hybrid:.4f} ({trend}, Œî{abs(delta):.1f}%)")

    # Save metrics JSON for dashboard
    save_metrics_to_json(metrics_base, metrics_hybrid)


========== FILE: src/optimize_latent.py ==========

import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import os
import matplotlib.pyplot as plt
from src.model import XylemAutoencoder
from src.train_surrogate import PhysicsSurrogateCNN

# CONFIG
MODEL_PATH = "results/model_physics_tuned.pth"
SURROGATE_PATH = "results/physics_surrogate.pth"
OUTPUT_DIR = "results/inverse_design/"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ---------------------------------------------------------
# Differentiable Heuristics
# ---------------------------------------------------------

def calc_stiffness_proxy(image):
    """
    Heuristic: E ~ rho^2. 
    Density (rho) = 1.0 - mean_pixel_value (assuming 0=Solid, 1=Void in normalized space)
    """
    # Normalize image to 0-1 range just in case
    img_min, img_max = image.min(), image.max()
    norm_img = (image - img_min) / (img_max - img_min + 1e-6)
    
    # Calculate relative porosity (bright pixels)
    # Density is the inverse of porosity
    density = 1.0 - torch.mean(norm_img, dim=[1, 2, 3])
    return density ** 2

def total_variation_loss(img):
    """
    Differentiable proxy for 'connectivity'.
    Penalizes noise and disconnected pixel dust.
    """
    b, c, h, w = img.size()
    tv_h = torch.pow(img[:, :, 1:, :] - img[:, :, :-1, :], 2).sum()
    tv_w = torch.pow(img[:, :, :, 1:] - img[:, :, :, :-1], 2).sum()
    return (tv_h + tv_w) / (b * c * h * w)

# ---------------------------------------------------------
# Optimization Loop
# ---------------------------------------------------------

def inverse_design(ae, surrogate, target_flow, target_stiffness, steps=200):
    device = next(ae.parameters()).device
    
    # 1. Initialize Z (Random Gaussian)
    latent_dim = 32
    z = torch.randn(1, latent_dim, device=device, requires_grad=True)
    
    # 2. Optimizer
    optimizer = optim.Adam([z], lr=0.05)
    
    # Weights for the Multi-Objective Optimization
    w_flow = 20.0      # Priority 1: Match Flow
    w_stiff = 10.0     # Priority 2: Match Stiffness
    w_tv = 0.1         # Priority 3: Keep it clean (connected)
    
    history = []

    print(f"üéØ Target: Flow={target_flow:.4f}, Stiffness={target_stiffness:.4f}")

    for i in range(steps):
        optimizer.zero_grad()
        
        # Forward Pass
        recon = ae.decode(z)
        
        # Physics Prediction (Surrogate)
        # Surrogate outputs: [Mean_K, Mean_dP/dy, FlowRate, Porosity, Anisotropy]
        # We want to match FlowRate (index 2)
        surrogate_preds = surrogate(recon)
        current_flow = surrogate_preds[:, 2] 
        
        # Stiffness Calculation
        current_stiffness = calc_stiffness_proxy(recon)
        
        # Loss Calculation
        loss_flow = (current_flow - target_flow) ** 2
        loss_stiff = (current_stiffness - target_stiffness) ** 2
        loss_tv = total_variation_loss(recon)
        
        total_loss = (w_flow * loss_flow) + (w_stiff * loss_stiff) + (w_tv * loss_tv)
        
        total_loss.backward()
        optimizer.step()
        
        if i % 50 == 0:
            print(f"   Step {i:03d}: Flow={current_flow.item():.4f}, Stiff={current_stiffness.item():.4f} | Loss={total_loss.item():.4f}")
            
        history.append({
            'step': i,
            'flow': current_flow.item(),
            'stiffness': current_stiffness.item(),
            'loss': total_loss.item()
        })

    return z.detach(), recon.detach(), pd.DataFrame(history)

# ---------------------------------------------------------
# Main Execution
# ---------------------------------------------------------

def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Load Autoencoder
    print("‚è≥ Loading Autoencoder...")
    checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)
    ae = XylemAutoencoder().to(device)
    if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
        ae.load_state_dict(checkpoint['state_dict'])
    elif isinstance(checkpoint, dict):
        ae.load_state_dict(checkpoint)
    else:
        ae.load_state_dict(checkpoint.state_dict())
    ae.eval()
    
    # Load Surrogate
    print("‚è≥ Loading Physics Surrogate...")
    surrogate = PhysicsSurrogateCNN().to(device)
    surrogate_ckpt = torch.load(SURROGATE_PATH, map_location=device, weights_only=False)
    if isinstance(surrogate_ckpt, dict):
        surrogate.load_state_dict(surrogate_ckpt)
    else:
        surrogate.load_state_dict(surrogate_ckpt.state_dict())
    surrogate.eval()
    
    # --- DESIGN SWEEP ---
    # These are the specific engineering specs we want to invent
    targets = [
        {"name": "HighFlow_Flexible", "f": 0.0010, "s": 0.2}, # Like a sponge
        {"name": "Balanced_Hybrid",   "f": 0.0008, "s": 0.5}, # Like real xylem
        {"name": "LowFlow_Stiff",     "f": 0.0004, "s": 0.8}, # Like a brick
    ]
    
    for t in targets:
        print(f"\nüöÄ Inverse Designing: {t['name']}")
        z_opt, img_opt, hist = inverse_design(ae, surrogate, t['f'], t['s'])
        
        # Save Structure
        img_np = img_opt.cpu().squeeze().numpy()
        plt.imsave(os.path.join(OUTPUT_DIR, f"{t['name']}_structure.png"), img_np, cmap='gray_r')
        
        # Save Convergence Plot
        plt.figure(figsize=(10,4))
        plt.plot(hist['step'], hist['flow'], label='Flow Rate', color='blue')
        plt.plot(hist['step'], hist['stiffness'], label='Stiffness', color='orange')
        plt.axhline(y=t['f'], color='blue', linestyle='--', alpha=0.5, label='Target Flow')
        plt.axhline(y=t['s'], color='orange', linestyle='--', alpha=0.5, label='Target Stiff')
        plt.legend()
        plt.title(f"Optimization Trajectory: {t['name']}")
        plt.savefig(os.path.join(OUTPUT_DIR, f"{t['name']}_trajectory.png"))
        plt.close()

    print("\n‚úÖ Design Sweep Complete. Check 'results/inverse_design/' for your artifacts.")

if __name__ == "__main__":
    main()

========== FILE: src/optimize_latent_thermal.py ==========

import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import os
import matplotlib.pyplot as plt
import numpy as np
from src.model import XylemAutoencoder 
from src.train_thermal_surrogate import ThermalSurrogate # Import your new model class

# CONFIG
MODEL_PATH = "results/model_physics_tuned.pth"
THERMAL_SURROGATE_PATH = "results/thermal_surrogate.pth"
OUTPUT_DIR = "results/thermal_design/"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ---------------------------------------------------------
# Optimization Loop (Thermal Edition)
# ---------------------------------------------------------

def inverse_design_thermal(ae, surrogate, meta, target_q, target_rho, steps=200):
    device = next(ae.parameters()).device
    
    # 1. Initialize Z
    latent_dim = 32
    z = torch.randn(1, latent_dim, device=device, requires_grad=True)
    
    # 2. Optimizer
    optimizer = optim.Adam([z], lr=0.05)
    
    # Weights 
    w_q = 20.0     # Priority 1: Hit Flux Target
    w_rho = 10.0   # Priority 2: Hit Density Target
    
    # Normalization stats from training metadata
    q_mean, q_std = meta['q_mean'], meta['q_std']
    rho_mean, rho_std = meta['rho_mean'], meta['rho_std']
    
    # Normalize Targets (so they match surrogate output space)
    target_q_norm = (target_q - q_mean) / q_std
    target_rho_norm = (target_rho - rho_mean) / rho_std
    
    history = []

    print(f"üéØ Target: Flux={target_q:.4f}, Density={target_rho:.4f}")

    for i in range(steps):
        optimizer.zero_grad()
        
        # Generator
        recon = ae.decode(z)
        
        # Thermal Surrogate Prediction
        # Output: [Q_norm, Rho_norm]
        preds = surrogate(recon)
        pred_q_norm = preds[:, 0]
        pred_rho_norm = preds[:, 1]
        
        # Losses (in normalized space)
        loss_q = (pred_q_norm - target_q_norm) ** 2
        loss_rho = (pred_rho_norm - target_rho_norm) ** 2
        
        total_loss = (w_q * loss_q) + (w_rho * loss_rho) 
        
        total_loss.backward()
        optimizer.step()
        
        # Un-normalize for logging
        current_q = (pred_q_norm.item() * q_std) + q_mean
        current_rho = (pred_rho_norm.item() * rho_std) + rho_mean
        
        if i % 50 == 0:
            print(f"   Step {i:03d}: Flux={current_q:.4f}, Rho={current_rho:.4f} | Loss={total_loss.item():.4f}")
            
        history.append({
            'step': i,
            'flux': current_q,
            'density': current_rho,
            'loss': total_loss.item()
        })

    return z.detach(), recon.detach(), pd.DataFrame(history)

# ---------------------------------------------------------
# Main Execution
# ---------------------------------------------------------

def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Load Autoencoder (Geometry)
    print("‚è≥ Loading Geometry Model...")
    checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)
    ae = XylemAutoencoder().to(device)
    if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
        ae.load_state_dict(checkpoint['state_dict'])
    else:
        ae.load_state_dict(checkpoint)
    ae.eval()
    
    # Load Thermal Surrogate (Physics)
    print("‚è≥ Loading Thermal Surrogate...")
    surrogate = ThermalSurrogate().to(device)
    surr_checkpoint = torch.load(THERMAL_SURROGATE_PATH, map_location=device, weights_only=False)
    
    # Load weights and metadata
    surrogate.load_state_dict(surr_checkpoint['state_dict'])
    meta = {k: v for k, v in surr_checkpoint.items() if k != 'state_dict'}
    surrogate.eval()
    
    # --- DESIGN SWEEP ---
    # Targets based on your dataset stats:
    # Q range: 0.05 - 0.14
    # Rho range: 0.07 - 0.60
    
    targets = [
        {"name": "MaxCooling_Heavy", "q": 0.14, "r": 0.60}, # Max performance, heavy
        {"name": "Balanced_Sink",    "q": 0.10, "r": 0.35}, # Good cooling, light
        {"name": "Lightweight_Fin",  "q": 0.07, "r": 0.15}, # Minimal material
    ]
    
    for t in targets:
        print(f"\nüöÄ Inverse Designing: {t['name']}")
        z_opt, img_opt, hist = inverse_design_thermal(ae, surrogate, meta, t['q'], t['r'])
        
        # Save Structure
        img_np = img_opt.cpu().squeeze().numpy()
        plt.imsave(os.path.join(OUTPUT_DIR, f"{t['name']}_structure.png"), img_np, cmap='inferno')
        
        # Save Convergence Plot
        plt.figure(figsize=(10,4))
        plt.plot(hist['step'], hist['flux'], label='Flux (Q)', color='red')
        plt.plot(hist['step'], hist['density'], label='Density (Rho)', color='grey')
        plt.axhline(y=t['q'], color='red', linestyle='--', alpha=0.5, label='Target Flux')
        plt.axhline(y=t['r'], color='grey', linestyle='--', alpha=0.5, label='Target Rho')
        plt.legend()
        plt.title(f"Thermal Optimization: {t['name']}")
        plt.savefig(os.path.join(OUTPUT_DIR, f"{t['name']}_trajectory.png"))
        plt.close()

    print("\n‚úÖ Thermal Design Sweep Complete. Check 'results/thermal_design/'")

if __name__ == "__main__":
    main()

========== FILE: src/optimize_structures.py ==========

"""
optimize_structures.py
Search the latent space for synthetic xylem designs with high simulated conductivity.
"""

import os, sys, subprocess
import numpy as np
import torch
import matplotlib.pyplot as plt
from torchvision.utils import save_image

# --- dependencies ---
REQUIRED = ["torch", "torchvision", "numpy", "matplotlib", "Pillow"]
for pkg in REQUIRED:
    try:
        __import__(pkg)
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install", pkg])

# --- paths ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(CURRENT_DIR)
RESULTS_DIR = os.path.join(ROOT_DIR, "results", "optimization")
os.makedirs(RESULTS_DIR, exist_ok=True)

# --- import project modules ---
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

try:
    from src.model import XylemAutoencoder
    from src.simulate_flow import simulate_pressure_field, compute_conductivity
except ModuleNotFoundError:
    import model
    from simulate_flow import simulate_pressure_field, compute_conductivity

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
LATENT_DIM = 32
ITERATIONS = 20
POP_SIZE = 8
STEP = 0.05

# --- decode latent vector into image tensor ---
def decode_structure(model, z):
    """
    Converts latent vector z ‚Üí reconstructed 256x256 image tensor.
    Handles reshaping to match decoder input.
    """
    with torch.no_grad():
        # fully-connected reconstruction to feature map
        flat = model.fc_dec(z)
        # reshape: (batch, channels=128, height=16, width=16)
        feature = flat.view(-1, 128, 16, 16)
        recon = model.decoder_deconv(feature)
        return recon

# --- main routine ---
def main():
    model = XylemAutoencoder(latent_dim=LATENT_DIM).to(DEVICE)
    dummy = torch.zeros(1, 1, 256, 256).to(DEVICE)
    _ = model(dummy)  # build internal layers
    state_dict = torch.load(os.path.join(ROOT_DIR, "results", "xylem_autoencoder.pt"), map_location=DEVICE)
    model.load_state_dict(state_dict, strict=False)
    model.eval()

    # initialize latent population
    z = torch.randn(POP_SIZE, LATENT_DIM, device=DEVICE)
    best_score = -1
    best_img = None

    for it in range(ITERATIONS):
        scores = []
        for i in range(POP_SIZE):
            recon = decode_structure(model, z[i:i+1]).cpu().numpy()[0, 0]
            p_field, mask = simulate_pressure_field(recon)
            cond = compute_conductivity(p_field, mask)
            scores.append(cond)

        scores = np.array(scores)
        best_idx = np.argmax(scores)

        if scores[best_idx] > best_score:
            best_score = scores[best_idx]
            best_img = decode_structure(model, z[best_idx:best_idx+1])
            save_image(best_img, os.path.join(RESULTS_DIR, f"best_iter_{it+1}.png"))

        print(f"Iter {it+1}/{ITERATIONS} | Best conductivity: {scores[best_idx]:.5f}")

        # evolve latent vectors toward top performer
        elite = z[best_idx].unsqueeze(0)
        noise = torch.randn_like(z) * STEP
        z = elite + noise

    save_image(best_img, os.path.join(RESULTS_DIR, "optimized_structure.png"))
    print(f"‚úÖ Optimization complete. Best conductivity = {best_score:.5f}")
    print(f"Results saved to {RESULTS_DIR}")

if __name__ == "__main__":
    main()


========== FILE: src/preprocess_real_xylem.py ==========

import os
from PIL import Image
import numpy as np

# Correct raw and processed directories
INPUT_DIR = "data/real_xylem_raw"
OUTPUT_DIR = "data/real_xylem"
os.makedirs(OUTPUT_DIR, exist_ok=True)

def preprocess_image(image_path):
    img = Image.open(image_path).convert("L")
    arr = np.array(img, dtype=np.float32)

    # Normalize 0‚Äì1
    arr = (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)

    # Optional cleanup: binarize slightly to emphasize vessels
    arr[arr < 0.2] = 0.0
    arr[arr >= 0.2] = 1.0

    return Image.fromarray((arr * 255).astype(np.uint8))

def preprocess_all():
    if not os.path.exists(INPUT_DIR):
        raise FileNotFoundError(f"Input folder not found: {INPUT_DIR}")
    
    files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith((".png", ".jpg", ".jpeg"))]
    print(f"üìÇ Found {len(files)} real xylem images in {INPUT_DIR}")
    
    for fname in files:
        img = preprocess_image(os.path.join(INPUT_DIR, fname))
        img.save(os.path.join(OUTPUT_DIR, fname))
    
    print(f"‚úÖ Preprocessing complete. Normalized images saved ‚Üí {OUTPUT_DIR}")

if __name__ == "__main__":
    preprocess_all()


========== FILE: src/preview_3d.py ==========

import trimesh
import matplotlib.pyplot as plt
import numpy as np
import os

MESH_FILE = "results/gradient_beam/gradient_beam_3d.stl"
OUTPUT_IMG = "results/gradient_beam/3d_preview.png"

def main():
    if not os.path.exists(MESH_FILE):
        print("‚ùå STL file not found.")
        return

    print(f"üëÄ Loading mesh for preview...")
    mesh = trimesh.load(MESH_FILE)
    
    # Downsample: 1.3M points is too heavy for matplotlib. We take 5,000 random points.
    print(f"   Mesh has {len(mesh.vertices)} vertices. Sampling 5,000 for preview...")
    indices = np.random.choice(len(mesh.vertices), 5000, replace=False)
    points = mesh.vertices[indices]

    # Plot
    fig = plt.figure(figsize=(10, 6))
    ax = fig.add_subplot(111, projection='3d')
    
    # Scatter plot (X=Length, Y=Width, Z=Height)
    # Coloring by Z (Height) to show layers
    ax.scatter(points[:,0], points[:,1], points[:,2], c=points[:,2], cmap='viridis', s=1, alpha=0.6)
    
    # Clean up axis
    ax.set_title("3D Gradient Beam (Point Cloud Preview)")
    ax.set_xlabel("Length (X)")
    ax.set_ylabel("Width (Y)")
    ax.set_zlabel("Height (Z)")
    
    # Force Aspect Ratio so it doesn't look squashed
    # (Matplotlib 3D aspect ratio is tricky, usually requires manual box setting)
    
    plt.savefig(OUTPUT_IMG, dpi=100)
    print(f"‚úÖ Preview image saved to: {OUTPUT_IMG}")
    print("   Open this image to see your structure!")

if __name__ == "__main__":
    main()

========== FILE: src/requirements.txt ==========

torch
torchvision
matplotlib
numpy
Pillow


========== FILE: src/simulate_flow.py ==========

"""
simulate_flow.py
Couples learned xylem structures with a simplified 2D flow simulation.
Outputs conductivity metrics and visual flow maps.
"""

import os, sys, subprocess
import numpy as np
import torch
import matplotlib.pyplot as plt
from PIL import Image
from torchvision import transforms

# --- Auto-install missing packages ---
REQUIRED = ["numpy", "matplotlib", "torch", "torchvision", "Pillow"]
for pkg in REQUIRED:
    try:
        __import__(pkg)
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install", pkg])

# --- Paths ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(CURRENT_DIR)
DATA_DIR = os.path.join(ROOT_DIR, "data", "generated_microtubes")
RESULTS_DIR = os.path.join(ROOT_DIR, "results", "flow_simulation")
os.makedirs(RESULTS_DIR, exist_ok=True)

# --- Image loader ---
def load_structure(img_path):
    transform = transforms.Compose([
        transforms.Grayscale(),
        transforms.Resize((256, 256)),
        transforms.ToTensor()
    ])
    img = Image.open(img_path)
    tensor = transform(img).squeeze().numpy()
    return tensor

# --- Simple flow solver (steady-state Laplace approximation) ---
def simulate_pressure_field(structure, inlet=1.0, outlet=0.0, iterations=5000):
    """
    structure: 2D numpy array (1=solid, 0=void)
    Simulate a steady-state pressure gradient through open pores.
    """
    mask = (structure < 0.5).astype(float)  # 1=open channel, 0=solid wall
    p = np.zeros_like(mask)
    p[:, 0] = inlet
    p[:, -1] = outlet

    for _ in range(iterations):
        # Jacobi relaxation
        p_new = p.copy()
        p_new[1:-1, 1:-1] = 0.25 * (
            p[2:, 1:-1] + p[:-2, 1:-1] +
            p[1:-1, 2:] + p[1:-1, :-2]
        )
        p = p_new * mask + p * (1 - mask)  # enforce walls
        # boundary conditions
        p[:, 0] = inlet
        p[:, -1] = outlet
    return p, mask

# --- Compute conductivity metric ---
def compute_conductivity(p_field, mask):
    grad = np.gradient(p_field, axis=1)
    flow = -grad * mask
    mean_flow = np.abs(flow).mean()
    return mean_flow

# --- Main routine ---
def main():
    images = sorted([f for f in os.listdir(DATA_DIR) if f.endswith(".png")])
    metrics = []
    for f in images:
        path = os.path.join(DATA_DIR, f)
        structure = load_structure(path)
        p_field, mask = simulate_pressure_field(structure)
        cond = compute_conductivity(p_field, mask)
        metrics.append((f, cond))

        # Visualize pressure field
        plt.imshow(p_field, cmap="coolwarm")
        plt.title(f"Pressure field: {f}\nConductivity={cond:.4f}")
        plt.axis("off")
        plt.tight_layout()
        plt.savefig(os.path.join(RESULTS_DIR, f"flow_{f}.png"))
        plt.close()

    # Save summary
    metrics.sort(key=lambda x: x[1], reverse=True)
    with open(os.path.join(RESULTS_DIR, "conductivity_metrics.txt"), "w") as f:
        for name, val in metrics:
            f.write(f"{name}\t{val:.6f}\n")

    print(f"‚úÖ Flow simulation complete. Results in {RESULTS_DIR}")

if __name__ == "__main__":
    main()


========== FILE: src/sweep_design_grid.py ==========

import torch
import numpy as np
import matplotlib.pyplot as plt
import os
from src.model import XylemAutoencoder
from src.train_thermal_surrogate import ThermalSurrogate
from src.optimize_latent_thermal import inverse_design_thermal

# CONFIG
MODEL_PATH = "results/model_physics_tuned.pth"
SURROGATE_PATH = "results/thermal_surrogate.pth"
OUTPUT_DIR = "results/thermal_design/"
GRID_SIZE = 5  # 5x5 grid

def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üöÄ Starting Design Sweep ({GRID_SIZE}x{GRID_SIZE})...")
    
    # 1. Load Models
    # Geometry
    ckpt_ae = torch.load(MODEL_PATH, map_location=device, weights_only=False)
    ae = XylemAutoencoder().to(device)
    if isinstance(ckpt_ae, dict) and 'state_dict' in ckpt_ae:
        ae.load_state_dict(ckpt_ae['state_dict'])
    else:
        ae.load_state_dict(ckpt_ae)
    ae.eval()
    
    # Physics
    surrogate = ThermalSurrogate().to(device)
    ckpt_surr = torch.load(SURROGATE_PATH, map_location=device, weights_only=False)
    surrogate.load_state_dict(ckpt_surr['state_dict'])
    
    # Metadata for normalization
    meta = {k: v for k, v in ckpt_surr.items() if k != 'state_dict'}
    surrogate.eval()
    
    # 2. Define Targets
    # Flux (Q) range: 0.06 to 0.14
    # Density (Rho) range: 0.20 to 0.60
    target_qs = np.linspace(0.06, 0.14, GRID_SIZE)
    target_rhos = np.linspace(0.20, 0.60, GRID_SIZE)
    
    # 3. The Grid Loop
    # We will stitch images into a large canvas
    canvas = np.zeros((256 * GRID_SIZE, 256 * GRID_SIZE))
    
    print("   Generating grid...")
    
    for i, q in enumerate(target_qs):      # Rows (Flux)
        for j, r in enumerate(target_rhos): # Cols (Density)
            print(f"   [{i},{j}] Target: Q={q:.3f}, Rho={r:.3f}...", end="\r")
            
            # Run Inverse Design (Fast mode: fewer steps)
            z_opt, img_opt, _ = inverse_design_thermal(
                ae, surrogate, meta, 
                target_q=q, target_rho=r, 
                steps=100
            )
            
            # Convert to numpy
            tile = img_opt.cpu().detach().squeeze().numpy()
            
            # Insert into canvas
            # Note: We flip i to make Flux increase UPWARDS in the plot if desired, 
            # or just standard matrix order. Let's do standard matrix:
            # Row i, Col j
            r_start, r_end = i*256, (i+1)*256
            c_start, c_end = j*256, (j+1)*256
            canvas[r_start:r_end, c_start:c_end] = tile
            
    print("\n‚úÖ Grid generation complete.")
    
    # 4. Save
    plt.figure(figsize=(10, 10))
    plt.imshow(canvas, cmap='inferno')
    plt.title(f"Generative Design Manifold ({GRID_SIZE}x{GRID_SIZE})\nX-axis: Density (0.2->0.6) | Y-axis: Cooling (0.06->0.14)")
    plt.axis('off')
    
    save_path = os.path.join(OUTPUT_DIR, "design_manifold.png")
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"üñºÔ∏è  Manifold saved to: {save_path}")

if __name__ == "__main__":
    main()

========== FILE: src/synthetic_cambium.py ==========

"""
synthetic_cambium.py
----------------------------------------
Simulates adaptive vascular growth (synthetic cambium), where a trained
autoencoder "grows" vascular-like structures based on feedback from
a fluid-flow simulation.

This models how real trees reinforce xylem tissue in response
to pressure gradients ‚Äî closing the loop between structure and flow.
"""

import os, sys, torch, numpy as np, matplotlib.pyplot as plt

# --- Ensure imports work both in Camber and locally ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(CURRENT_DIR)
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

# --- Project modules ---
from src.model import XylemAutoencoder
from src.simulate_flow import simulate_pressure_field, compute_conductivity

# --- Config ---
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
LATENT_DIM = 32
ITERATIONS = 20
ALPHA = 0.1  # growth learning rate (like cambial sensitivity)
SAVE_DIR = os.path.join(ROOT_DIR, "results", "cambium_growth")
os.makedirs(SAVE_DIR, exist_ok=True)


# ======================================================================
# Helper functions
# ======================================================================

def decode_structure(model, z):
    """
    Decode latent vector z ‚Üí vascular structure image.
    Automatically detects which decoder attribute the model uses.
    Ensures correct reshaping before ConvTranspose2d layers.
    """
    with torch.no_grad():
        # Fully connected expansion from latent to feature map
        x = model.fc_dec(z)

        # Reshape for convolutional decoder (matches model.py)
        x = x.view(-1, 128, 16, 16)

        # Choose appropriate decoder
        if hasattr(model, "decoder_conv"):
            decoded = model.decoder_conv(x)
        elif hasattr(model, "decoder"):
            decoded = model.decoder(x)
        elif hasattr(model, "deconv"):
            decoded = model.deconv(x)
        else:
            raise AttributeError("‚ùå Model missing decoder attribute (decoder / decoder_conv / deconv).")

        # Ensure correct dimensionality (B,C,H,W)
        if len(decoded.shape) != 4:
            raise RuntimeError(f"Unexpected decoded shape: {decoded.shape}")

        return decoded


def growth_cycle(model, z):
    """
    Perform one iteration of adaptive growth:
      1. Decode latent z into a vascular structure.
      2. Simulate pressure and flow field.
      3. Compute conductivity and gradient feedback.
      4. Update z based on the feedback ("growth rule").
    """
    recon = decode_structure(model, z)
    img = recon.detach().cpu().numpy()[0, 0]

    # Simulate pressure field and compute effective conductivity
    p_field, mask = simulate_pressure_field(img)
    conductivity = compute_conductivity(p_field, mask)

    # Compute feedback ‚Äî mean gradient of pressure field
    grad_proxy = torch.tensor(np.mean(np.gradient(p_field)), dtype=torch.float32).to(DEVICE)

    # Update latent space ("growth" step)
    z_new = z + ALPHA * grad_proxy
    z_new = z_new / torch.norm(z_new)  # normalize latent vector (stability)

    return z_new, conductivity, img, p_field


# ======================================================================
# Main simulation loop
# ======================================================================

def main():
    print("üåø Running Synthetic Cambium Growth Loop...")

    # Initialize model
    model = XylemAutoencoder(latent_dim=LATENT_DIM).to(DEVICE)

    # --- Load pretrained model safely ---
    state_path = os.path.join(ROOT_DIR, "results", "xylem_autoencoder.pt")
    if not os.path.exists(state_path):
        raise FileNotFoundError(f"‚ùå Model weights not found at {state_path}")

    print("‚öôÔ∏è Loading pretrained weights (ignoring size mismatches)...")
    state_dict = torch.load(state_path, map_location=DEVICE)
    model_state = model.state_dict()

    # Only keep matching layer shapes
    filtered_state = {
        k: v for k, v in state_dict.items()
        if k in model_state and v.shape == model_state[k].shape
    }

    # Load compatible weights
    missing, unexpected = model.load_state_dict(filtered_state, strict=False)
    print(f"‚úÖ Loaded {len(filtered_state)} compatible layers, "
          f"skipped {len(model_state) - len(filtered_state)} mismatched ones.")

    model.eval()

    # --- Initialize random latent vector (the 'cambium seed') ---
    z = torch.randn(1, LATENT_DIM, device=DEVICE)
    conductivity_history = []

    # --- Growth iterations ---
    for i in range(ITERATIONS):
        z, cond, img, field = growth_cycle(model, z)
        conductivity_history.append(cond)

        # Save visualization
        plt.imshow(img, cmap="gray")
        plt.axis("off")
        plt.title(f"Iteration {i+1} | Conductivity: {cond:.4f}")
        plt.savefig(os.path.join(SAVE_DIR, f"growth_{i:03d}.png"),
                    bbox_inches="tight", pad_inches=0)
        plt.close()

        print(f"Iteration {i+1}/{ITERATIONS} | Conductivity: {cond:.5f}")

    # Save final metrics
    np.savetxt(os.path.join(SAVE_DIR, "conductivity_history.txt"), conductivity_history)
    print(f"‚úÖ Synthetic cambium growth complete. Results saved to: {SAVE_DIR}")


# ======================================================================
# Entrypoint
# ======================================================================

if __name__ == "__main__":
    main()


========== FILE: src/train.py ==========

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from src.model import Autoencoder

DATA_DIR = "data/real_xylem"
RESULTS_DIR = "results"
os.makedirs(RESULTS_DIR, exist_ok=True)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose([
    transforms.Grayscale(),
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Lambda(lambda x: (x - x.min()) / (x.max() - x.min() + 1e-8))
])

dataset = datasets.ImageFolder(DATA_DIR, transform=transform)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)

model = Autoencoder().to(DEVICE)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)

EPOCHS = 50
for epoch in range(EPOCHS):
    model.train()
    epoch_loss = 0
    for imgs, _ in dataloader:
        imgs = imgs.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, imgs)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
    print(f"Epoch [{epoch+1}/{EPOCHS}] Loss: {epoch_loss / len(dataloader):.6f}")

torch.save(model.state_dict(), os.path.join(RESULTS_DIR, "model_base.pth"))
print(f"‚úÖ Training complete. Model saved ‚Üí {RESULTS_DIR}/model_base.pth")


========== FILE: src/train_hybrid.py ==========

"""
train_hybrid.py
Fine-tunes the XylemAutoencoder on a hybrid dataset:
real xylem (data/real_xylem_preprocessed)
+ synthetic xylem (data/generated_microtubes)
to align latent spaces and increase morphological realism.
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from src.model import XylemAutoencoder

# -------------------------------
# Configuration
# -------------------------------
REAL_DIR = "data/real_xylem_preprocessed"
SYN_DIR = "data/generated_microtubes"
SAVE_DIR = "results/hybrid_training"
os.makedirs(SAVE_DIR, exist_ok=True)

torch.backends.cudnn.benchmark = True
BATCH_SIZE = 8
EPOCHS = 20
LR = 1e-4
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_PATH = "results/model.pth"

# -------------------------------
# Dataset
# -------------------------------
class XylemHybridDataset(Dataset):
    def __init__(self, real_dir, syn_dir, transform=None):
        self.real_files = [os.path.join(real_dir, f)
                           for f in os.listdir(real_dir)
                           if f.lower().endswith((".png", ".jpg", ".jpeg"))]
        self.syn_files = [os.path.join(syn_dir, f)
                          for f in os.listdir(syn_dir)
                          if f.lower().endswith((".png", ".jpg", ".jpeg"))]
        self.all_files = self.real_files + self.syn_files
        self.labels = [0] * len(self.real_files) + [1] * len(self.syn_files)
        self.transform = transform

    def __len__(self):
        return len(self.all_files)

    def __getitem__(self, idx):
        img_path = self.all_files[idx]
        label = self.labels[idx]
        img = Image.open(img_path).convert("L")
        if self.transform:
            img = self.transform(img)
        return img, label

# -------------------------------
# Transform
# -------------------------------
transform = transforms.Compose([
    transforms.Grayscale(),
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

dataset = XylemHybridDataset(REAL_DIR, SYN_DIR, transform)
dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

# -------------------------------
# Model Setup
# -------------------------------
model = XylemAutoencoder(latent_dim=32).to(DEVICE)
checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
model_dict = model.state_dict()
compatible_dict = {k: v for k, v in checkpoint.items()
                   if k in model_dict and v.shape == model_dict[k].shape}
model_dict.update(compatible_dict)
model.load_state_dict(model_dict)
print(f"‚úÖ Loaded {len(compatible_dict)} compatible layers from {MODEL_PATH}")

criterion_recon = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=LR)

# -------------------------------
# Training Loop
# -------------------------------
print(f"üöÄ Starting hybrid fine-tuning for {EPOCHS} epochs on {DEVICE}")
for epoch in range(EPOCHS):
    total_loss, total_recon, total_align = 0, 0, 0
    for imgs, labels in dataloader:
        imgs = imgs.to(DEVICE)
        optimizer.zero_grad()

        recon, z = model(imgs)

        # Reconstruction loss
        loss_recon = criterion_recon(recon, imgs)

        # Latent alignment loss (push real & synthetic closer)
        z_real = z[labels == 0]
        z_syn = z[labels == 1]
        if len(z_real) > 0 and len(z_syn) > 0:
            loss_align = torch.mean((z_real.mean(0) - z_syn.mean(0)) ** 2)
        else:
            loss_align = torch.tensor(0.0, device=DEVICE)

        loss = loss_recon + 0.1 * loss_align
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        total_recon += loss_recon.item()
        total_align += loss_align.item()

    print(f"Epoch {epoch+1}/{EPOCHS} | "
          f"Loss: {total_loss/len(dataloader):.4f} | "
          f"Recon: {total_recon/len(dataloader):.4f} | "
          f"Align: {total_align/len(dataloader):.4f}")

# -------------------------------
# Save Model
# -------------------------------
save_path = os.path.join(SAVE_DIR, "model_hybrid.pth")
torch.save(model.state_dict(), save_path)
print(f"‚úÖ Hybrid fine-tuning complete. Model saved to {save_path}")


========== FILE: src/train_physics_informed.py ==========

"""
train_physics_informed.py  (v0.4 ‚Äì physics-dominant, porosity-weighted)

Fine-tune the XylemAutoencoder using a learned physics surrogate.

Pipeline:
  - Load autoencoder (results/model_hybrid.pth)
  - Load physics surrogate CNN (results/physics_surrogate.pth)
  - Load generated microtubes as training images
  - Load REAL xylem solver stats as physics targets from
    results/flow_metrics/flow_metrics.csv  (Type == "Real")
  - For each epoch:
      recon = AE(imgs)
      pred_metrics = surrogate(recon)
      physics_loss = weighted sum of per-metric squared errors, with
                     porosity error upweighted
      total_loss = RECON_WEIGHT * recon_loss + Œª_phys * physics_loss
  - Save tuned AE to results/model_physics_tuned.pth
  - Save full training log to results/physics_training_log.csv
"""

import os
import numpy as np
import pandas as pd
from PIL import Image

import torch
import torch.nn as nn
import torch.optim as optim

from src.model import XylemAutoencoder
from src.train_surrogate import PhysicsSurrogateCNN  # single source of truth

DEVICE = torch.device("cpu")
TARGET_SIZE = (256, 256)

# --------------------
# Loss weights
# --------------------
# How much we care about pixel-wise reconstruction vs physics.
# Physics-dominant: recon is down-weighted, physics is up-weighted.
RECON_WEIGHT = 0.1          # was 1.0 before

# Global ramp for physics influence over epochs
LAMBDA_PHYS_START = 3.0
LAMBDA_PHYS_END   = 20.0

NUM_EPOCHS = 100

# Per-metric physics weights
# (Names correspond to columns: Mean_K, Mean_dP/dy, FlowRate, Porosity, Anisotropy)
K_WEIGHT        = 1.0   # permeability
DPDY_WEIGHT     = 1.0   # pressure gradient
FLOW_WEIGHT     = 1.0   # flowrate
POROSITY_WEIGHT = 10.0  # aggressively push porosity toward target
ANISO_WEIGHT    = 1.0   # anisotropy


# ----------------------------------------------------
# Data loading
# ----------------------------------------------------
def load_and_preprocess_images(path: str) -> torch.Tensor:
    """Load and resize all grayscale images from a folder to consistent size."""
    imgs = []
    for f in sorted(os.listdir(path)):
        if f.lower().endswith((".png", ".jpg", ".jpeg", ".tif")):
            img = Image.open(os.path.join(path, f)).convert("L")
            img = img.resize(TARGET_SIZE, Image.BILINEAR)
            arr = np.array(img, dtype=np.float32) / 255.0
            imgs.append(torch.from_numpy(arr).unsqueeze(0))  # [1, H, W]
    if not imgs:
        raise RuntimeError(f"No images found in {path}")
    return torch.stack(imgs)  # [N, 1, H, W]


# ----------------------------------------------------
# Load real-physics targets from flow_metrics.csv
# ----------------------------------------------------
def load_real_targets(flow_metrics_path: str = "results/flow_metrics/flow_metrics.csv"):
    """
    Reads solver stats and returns mean targets for:
    [Mean_K, Mean_dP/dy, FlowRate, Porosity, Anisotropy] for REAL samples.
    """
    if not os.path.exists(flow_metrics_path):
        raise FileNotFoundError(
            f"Flow metrics file not found at {flow_metrics_path}. "
            "Run flow_simulation.py first."
        )

    df = pd.read_csv(flow_metrics_path)
    if "Type" in df.columns:
        df_real = df[df["Type"].str.lower() == "real"]
    else:
        df_real = df

    cols = ["Mean_K", "Mean_dP/dy", "FlowRate", "Porosity", "Anisotropy"]
    missing = [c for c in cols if c not in df_real.columns]
    if missing:
        raise ValueError(f"Missing expected columns in flow_metrics.csv: {missing}")

    targets_np = df_real[cols].mean(axis=0).to_numpy(dtype=np.float32)
    print("üéØ Real-physics targets from solver:")
    for name, val in zip(cols, targets_np):
        print(f"   {name:12s} ‚âà {val:.6f}")

    targets = torch.from_numpy(targets_np).to(DEVICE)
    return targets, cols


# ----------------------------------------------------
# Main training loop
# ----------------------------------------------------
def main():
    print("üå± Surrogate-based physics fine-tuning started on cpu")

    # 1) Load autoencoder
    ae = XylemAutoencoder().to(DEVICE)
    ae.load_state_dict(torch.load("results/model_hybrid.pth", map_location=DEVICE))
    ae.train()

    # 2) Load fixed surrogate (same arch as in train_surrogate.py)
    surrogate = PhysicsSurrogateCNN().to(DEVICE)
    surrogate.load_state_dict(torch.load("results/physics_surrogate.pth", map_location=DEVICE))
    surrogate.eval()
    for p in surrogate.parameters():
        p.requires_grad = False  # freeze weights; we only backprop through AE

    # 3) Load physics targets from REAL xylem solver metrics
    target_vec, metric_names = load_real_targets("results/flow_metrics/flow_metrics.csv")

    # Map metric names to indices for clarity
    metric_index = {name: i for i, name in enumerate(metric_names)}

    # 4) Load training images (synthetic microtubes)
    data_path = "data/generated_microtubes"
    imgs = load_and_preprocess_images(data_path).to(DEVICE)
    print(f"üß© Loaded {imgs.shape[0]} generated structures ‚Üí resized to {TARGET_SIZE}")

    recon_loss_fn = nn.MSELoss()
    optimizer = optim.Adam(ae.parameters(), lr=1e-4)

    logs = []

    for epoch in range(1, NUM_EPOCHS + 1):
        optimizer.zero_grad()

        # Forward through AE
        recon, _ = ae(imgs)
        recon_loss = recon_loss_fn(recon, imgs)

        # Surrogate predictions on reconstructions: [B, 5]
        pred_metrics = surrogate(recon)
        pred_mean = pred_metrics.mean(dim=0)  # [5]

        # Physics error vector
        diff = pred_mean - target_vec  # [5]

        # Extract per-metric squared errors by name
        loss_k    = diff[metric_index["Mean_K"]]      ** 2
        loss_dpdy = diff[metric_index["Mean_dP/dy"]]  ** 2
        loss_flow = diff[metric_index["FlowRate"]]    ** 2
        loss_por  = diff[metric_index["Porosity"]]    ** 2
        loss_aniso= diff[metric_index["Anisotropy"]]  ** 2

        # Weighted physics loss (porosity emphasized)
        phys_loss = (
            K_WEIGHT        * loss_k
            + DPDY_WEIGHT   * loss_dpdy
            + FLOW_WEIGHT   * loss_flow
            + POROSITY_WEIGHT * loss_por
            + ANISO_WEIGHT  * loss_aniso
        )

        # Gradually ramp global physics weight
        t = epoch / NUM_EPOCHS
        lambda_phys = LAMBDA_PHYS_START + (LAMBDA_PHYS_END - LAMBDA_PHYS_START) * t

        # Total loss: recon is down-weighted, physics dominates
        total_loss = RECON_WEIGHT * recon_loss + lambda_phys * phys_loss
        total_loss.backward()
        optimizer.step()

        # Gradient norm for monitoring
        grad_norm = 0.0
        for p in ae.parameters():
            if p.grad is not None:
                grad_norm += p.grad.norm().item()
        grad_norm = float(grad_norm)

        # Log row
        log_row = {
            "epoch": epoch,
            "total": float(total_loss.item()),
            # log the *unscaled* recon + weighted physics for interpretability
            "recon": float(recon_loss.item()),
            "phys": float(phys_loss.item()),
            "lambda_phys": float(lambda_phys),
            "recon_weight": float(RECON_WEIGHT),
            "loss_K": float(loss_k.item()),
            "loss_dPdy": float(loss_dpdy.item()),
            "loss_Flow": float(loss_flow.item()),
            "loss_Porosity": float(loss_por.item()),
            "loss_Anisotropy": float(loss_aniso.item()),
            "GradNorm": grad_norm,
        }
        # Also stash the current mean metrics (detached to CPU)
        for name, val in zip(metric_names, pred_mean.detach().cpu().numpy()):
            log_row[f"pred_{name}"] = float(val)

        logs.append(log_row)

        if epoch == 1 or epoch % 5 == 0:
            metrics_str = " | ".join(
                f"{name}: {log_row[f'pred_{name}']:.5f}" for name in metric_names
            )
            print(
                f"Epoch {epoch:3d}/{NUM_EPOCHS} | "
                f"Total: {log_row['total']:.5f} | "
                f"Recon(unscaled): {log_row['recon']:.5f} | "
                f"Phys(weighted): {log_row['phys']:.5f} | "
                f"Œª_phys: {log_row['lambda_phys']:.2f} | "
                f"{metrics_str} | "
                f"GradNorm: {grad_norm:.2e}"
            )

    # 5) Save tuned model + log
    os.makedirs("results", exist_ok=True)
    torch.save(ae.state_dict(), "results/model_physics_tuned.pth")
    pd.DataFrame(logs).to_csv("results/physics_training_log.csv", index=False)

    print("‚úÖ Surrogate-based physics fine-tuning complete.")
    print("üíæ Model saved ‚Üí results/model_physics_tuned.pth")
    print("üßæ Training log saved ‚Üí results/physics_training_log.csv")


if __name__ == "__main__":
    main()


========== FILE: src/train_physics_informed_v03.py ==========

"""
train_physics_informed_v03.py

Xylem v0.3:
- Uses the trained physics surrogate to match BOTH mean and variance
  of (K, dP/dy, FlowRate, Porosity, Anisotropy) to the REAL xylem
  distribution.

This leaves v0.2 intact and gives you a clearly labeled v0.3 experiment.
"""

import os
import math
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
from PIL import Image

from src.model import XylemAutoencoder
from src.train_surrogate import PhysicsSurrogateCNN  # uses the same class as when you trained the surrogate

DEVICE = torch.device("cpu")
TARGET_SIZE = (256, 256)

REAL_METRICS_CSV = "results/flow_metrics/flow_metrics.csv"
BASE_MODEL_PATH = "results/model_hybrid.pth"          # you can change to model_physics_informed.pth if you want
SURROGATE_PATH   = "results/physics_surrogate.pth"
OUT_MODEL_PATH   = "results/model_physics_v03.pth"
OUT_LOG_CSV      = "results/physics_training_log_v03.csv"


# -----------------------------
# Data loading
# -----------------------------
def load_and_preprocess_images(path):
    """Load and resize all grayscale images from a folder to consistent size."""
    imgs = []
    for f in sorted(os.listdir(path)):
        if f.lower().endswith((".png", ".jpg", ".jpeg", ".tif")):
            img = Image.open(os.path.join(path, f)).convert("L")
            img = img.resize(TARGET_SIZE, Image.BILINEAR)
            arr = np.array(img, dtype=np.float32) / 255.0
            imgs.append(torch.tensor(arr).unsqueeze(0))  # [1,H,W]
    if not imgs:
        raise RuntimeError(f"No images found in {path}")
    batch = torch.stack(imgs)  # [N,1,H,W]
    return batch.to(DEVICE)


# -----------------------------
# Real-xylem target stats
# -----------------------------
METRIC_COLUMNS = ["Mean_K", "Mean_dP/dy", "FlowRate", "Porosity", "Anisotropy"]

def load_real_targets(csv_path=REAL_METRICS_CSV):
    """
    Load real-xylem flow metrics and compute per-metric mean & variance.
    """
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"Real metrics CSV not found at {csv_path}")

    df = pd.read_csv(csv_path)

    # If there's a Type column, filter to real
    if "Type" in df.columns:
        real_df = df[df["Type"].str.lower() == "real"].copy()
        if real_df.empty:
            raise ValueError("No 'Real' rows found in flow_metrics.csv")
    else:
        real_df = df

    missing = [c for c in METRIC_COLUMNS if c not in real_df.columns]
    if missing:
        raise ValueError(f"Missing columns in real metrics CSV: {missing}")

    means = real_df[METRIC_COLUMNS].mean().values.astype(np.float32)
    vars_ = real_df[METRIC_COLUMNS].var(ddof=0).values.astype(np.float32)  # population variance

    return torch.tensor(means, device=DEVICE), torch.tensor(vars_, device=DEVICE)


# -----------------------------
# Training
# -----------------------------
def main():
    print("üå± Surrogate-based distributional physics fine-tuning (v0.3) started on", DEVICE)

    # 1) Load real-xylem targets
    real_means, real_vars = load_real_targets()
    eps = 1e-6
    print("üéØ Real-physics targets from solver (means):")
    for name, val in zip(METRIC_COLUMNS, real_means.tolist()):
        print(f"   {name:<10} ‚âà {val:.6f}")
    print("üéØ Real-physics targets from solver (vars):")
    for name, val in zip(METRIC_COLUMNS, real_vars.tolist()):
        print(f"   {name:<10} ‚âà {val:.6f}")

    # 2) Load model
    model = XylemAutoencoder().to(DEVICE)
    if not os.path.exists(BASE_MODEL_PATH):
        raise FileNotFoundError(f"Base model not found at {BASE_MODEL_PATH}")
    model.load_state_dict(torch.load(BASE_MODEL_PATH, map_location=DEVICE))
    model.train()

    # 3) Load surrogate
    surrogate = PhysicsSurrogateCNN().to(DEVICE)
    if not os.path.exists(SURROGATE_PATH):
        raise FileNotFoundError(f"Surrogate model not found at {SURROGATE_PATH}")
    surrogate.load_state_dict(torch.load(SURROGATE_PATH, map_location=DEVICE))
    surrogate.eval()  # frozen

    # 4) Load generated structures (same as v0.2)
    data_path = "data/generated_microtubes"
    imgs = load_and_preprocess_images(data_path)
    print(f"üß© Loaded {imgs.shape[0]} generated structures ‚Üí resized to {TARGET_SIZE}")

    recon_loss_fn = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    logs = []
    num_epochs = 100

    for epoch in range(1, num_epochs + 1):
        optimizer.zero_grad()

        recon, _ = model(imgs)
        recon_loss = recon_loss_fn(recon, imgs)

        # ---------- physics via surrogate ----------
        with torch.no_grad():
            # surrogate outputs 5 metrics per image
            preds = surrogate(recon).view(-1, len(METRIC_COLUMNS))  # [N,5]

        batch_means = preds.mean(dim=0)          # [5]
        batch_vars  = preds.var(dim=0, unbiased=False)  # [5]

        # mean + variance matching, normalised by real variance
        mean_term = ((batch_means - real_means) ** 2) / (real_vars + eps)
        var_term  = ((batch_vars  - real_vars)  ** 2) / ((real_vars + eps) ** 2)

        # weight variance lower than mean to start
        alpha_var = 0.3
        phys_loss_per_metric = mean_term + alpha_var * var_term
        phys_loss = phys_loss_per_metric.sum()

        # Œª_phys schedule (starts modest, ramps up)
        lambda_phys = 0.5 + 5.0 * (1.0 - math.exp(-epoch / 30.0))

        total_loss = recon_loss + lambda_phys * phys_loss
        total_loss.backward()
        optimizer.step()

        # quick logging of some metrics
        grad_norm = 0.0
        for p in model.parameters():
            if p.grad is not None:
                grad_norm += p.grad.norm().item() ** 2
        grad_norm = grad_norm ** 0.5

        log_row = {
            "epoch": epoch,
            "total": total_loss.item(),
            "recon": recon_loss.item(),
            "phys": phys_loss.item(),
            "lambda_phys": lambda_phys,
            "Mean_K": batch_means[0].item(),
            "Mean_dP_dy": batch_means[1].item(),
            "FlowRate": batch_means[2].item(),
            "Porosity": batch_means[3].item(),
            "Anisotropy": batch_means[4].item(),
            "Var_K": batch_vars[0].item(),
            "Var_dP_dy": batch_vars[1].item(),
            "Var_FlowRate": batch_vars[2].item(),
            "Var_Porosity": batch_vars[3].item(),
            "Var_Anisotropy": batch_vars[4].item(),
            "GradNorm": grad_norm,
        }
        logs.append(log_row)

        if epoch % 5 == 0 or epoch == 1:
            print(
                f"Epoch {epoch:3d}/{num_epochs} | "
                f"Total: {total_loss.item():.5f} | "
                f"Recon: {recon_loss.item():.5f} | "
                f"Phys: {phys_loss.item():.5f} | "
                f"Œª_phys: {lambda_phys:.2f} | "
                f"Porosity_mean: {batch_means[3].item():.5f}"
            )

    # save
    os.makedirs("results", exist_ok=True)
    torch.save(model.state_dict(), OUT_MODEL_PATH)
    pd.DataFrame(logs).to_csv(OUT_LOG_CSV, index=False)

    print("‚úÖ v0.3 physics fine-tuning complete.")
    print(f"üíæ Model saved ‚Üí {OUT_MODEL_PATH}")
    print(f"üßæ Training log saved ‚Üí {OUT_LOG_CSV}")


if __name__ == "__main__":
    main()


========== FILE: src/train_physics_informed_v04.py ==========

import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
from PIL import Image

from src.model import XylemAutoencoder
from src.train_surrogate import PhysicsSurrogateCNN  # same class you used to train the surrogate

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
IMG_SIZE = (256, 256)


# ----------------------------
# Data loading
# ----------------------------
def load_and_preprocess_images(path):
    """Load all images from a folder, convert to grayscale, resize, normalize to [0,1]."""
    imgs = []
    for fname in sorted(os.listdir(path)):
        if fname.lower().endswith((".png", ".jpg", ".jpeg", ".tif")):
            p = os.path.join(path, fname)
            img = Image.open(p).convert("L")
            img = img.resize(IMG_SIZE, Image.BILINEAR)
            arr = np.array(img, dtype=np.float32) / 255.0  # [H,W] in [0,1]
            imgs.append(torch.from_numpy(arr).unsqueeze(0))  # [1,H,W]
    if not imgs:
        raise RuntimeError(f"No images found in {path}")
    stack = torch.stack(imgs)  # [N,1,H,W]
    return stack.to(DEVICE)


# ----------------------------
# Helper: real-physics targets
# ----------------------------
def load_real_solver_stats(csv_path="results/flow_metrics/flow_metrics.csv"):
    """
    Load solver metrics and compute REAL-xylem means and variances.
    Expects columns: ['Mean_K','Mean_dP/dy','FlowRate','Porosity','Anisotropy','Type']
    """
    df = pd.read_csv(csv_path)
    if "Type" in df.columns:
        real = df[df["Type"].str.lower() == "real"].copy()
    else:
        real = df.copy()

    means = {
        "Mean_K": float(real["Mean_K"].mean()),
        "Mean_dP/dy": float(real["Mean_dP/dy"].mean()),
        "FlowRate": float(real["FlowRate"].mean()),
        "Porosity": float(real["Porosity"].mean()),
        "Anisotropy": float(real["Anisotropy"].mean()),
    }
    vars_ = {
        "Mean_K": float(real["Mean_K"].var(ddof=0) + 1e-12),
        "Mean_dP/dy": float(real["Mean_dP/dy"].var(ddof=0) + 1e-12),
        "FlowRate": float(real["FlowRate"].var(ddof=0) + 1e-12),
        "Porosity": float(real["Porosity"].var(ddof=0) + 1e-12),
        "Anisotropy": float(real["Anisotropy"].var(ddof=0) + 1e-12),
    }
    return means, vars_


# ----------------------------
# Porosity proxy from image
# ----------------------------
def porosity_proxy_from_image(batch):
    """
    Simple differentiable porosity proxy.

    Assumption: pores are darker than background ‚Üí high porosity ‚âà lots of dark pixels.
    So we use: porosity_proxy = mean(1 - intensity).

    If this turns out inverted when you look at images, we can flip it later.
    """
    # batch: [N,1,H,W] in [0,1]
    return (1.0 - batch).mean(dim=[1, 2, 3])  # [N]


# ----------------------------
# Training loop (v0.4)
# ----------------------------
def main():
    print("üåø Surrogate-based *porosity-aware* physics fine-tuning (v0.4) started on", DEVICE)

    # 1) Load real solver stats
    real_means, real_vars = load_real_solver_stats("results/flow_metrics/flow_metrics.csv")
    print("üéØ Real-physics targets from solver (means):")
    for k, v in real_means.items():
        print(f"   {k:<10} ‚âà {v:.6f}")
    print("üéØ Real-physics targets from solver (vars):")
    for k, v in real_vars.items():
        print(f"   {k:<10} ‚âà {v:.6f}")

    # 2) Load model + surrogate
    model = XylemAutoencoder().to(DEVICE)
    model.load_state_dict(torch.load("results/model_hybrid.pth", map_location=DEVICE))
    model.train()

    surrogate = PhysicsSurrogateCNN().to(DEVICE)
    surrogate.load_state_dict(torch.load("results/physics_surrogate.pth", map_location=DEVICE))
    surrogate.eval()  # we never train surrogate here

    # 3) Load synthetic images to fine-tune on
    data_path = "data/generated_microtubes"
    imgs = load_and_preprocess_images(data_path)
    print(f"üß© Loaded {imgs.shape[0]} generated structures ‚Üí resized to {IMG_SIZE}")

    # 4) Optimizer / loss
    optimizer = optim.Adam(model.parameters(), lr=1e-4)
    recon_loss_fn = nn.MSELoss()

    num_epochs = 100
    logs = []

    # handy scalars
    K_target = real_means["Mean_K"]
    dP_target = real_means["Mean_dP/dy"]
    Flow_target = real_means["FlowRate"]
    Por_target = real_means["Porosity"]
    Aniso_target = real_means["Anisotropy"]

    # weights for each metric inside physics loss (all in normalized space)
    w_K = 1.0
    w_dP = 0.5
    w_Flow = 1.0
    w_Aniso = 0.2
    w_Por_proxy = 2.0  # we care a lot about porosity looking like real

    for epoch in range(1, num_epochs + 1):
        optimizer.zero_grad()

        # Forward pass through AE
        recon, _ = model(imgs)
        recon_loss = recon_loss_fn(recon, imgs)

        # Physics surrogate predictions (no grad through surrogate weights)
        with torch.no_grad():
            surrogate_out = surrogate(recon)  # [N,5]

        # Mean over batch
        K_pred_mean = surrogate_out[:, 0].mean()
        dP_pred_mean = surrogate_out[:, 1].mean()
        Flow_pred_mean = surrogate_out[:, 2].mean()
        Por_pred_mean = surrogate_out[:, 3].mean()
        Aniso_pred_mean = surrogate_out[:, 4].mean()

        # Image-based porosity proxy (differentiable)
        por_proxy_batch = porosity_proxy_from_image(recon)  # [N]
        por_proxy_mean = por_proxy_batch.mean()

        # Normalized squared errors (divide by target^2 to put things in comparable scale)
        def norm_sq(err, target):
            return (err ** 2) / (target ** 2 + 1e-12)

        loss_K = norm_sq(K_pred_mean - K_target, K_target)
        loss_dP = norm_sq(dP_pred_mean - dP_target, max(abs(dP_target), 1e-4))
        loss_Flow = norm_sq(Flow_pred_mean - Flow_target, Flow_target)
        loss_Aniso = norm_sq(Aniso_pred_mean - Aniso_target, Aniso_target)
        loss_Por_proxy = norm_sq(por_proxy_mean - Por_target, Por_target)

        # Total physics loss (inside-batch)
        phys_loss = (
            w_K * loss_K
            + w_dP * loss_dP
            + w_Flow * loss_Flow
            + w_Aniso * loss_Aniso
            + w_Por_proxy * loss_Por_proxy
        )

        # Epoch-dependent physics weight Œª_phys
        # Start gentle, grow but not to insane values
        lambda_phys = 0.5 + 4.5 * (1.0 - np.exp(-epoch / 30.0))

        total_loss = recon_loss + lambda_phys * phys_loss
        total_loss.backward()
        optimizer.step()

        # simple grad norm for sanity
        grad_norm = 0.0
        for p in model.parameters():
            if p.grad is not None:
                grad_norm += p.grad.norm().item() ** 2
        grad_norm = grad_norm ** 0.5

        logs.append(
            {
                "epoch": epoch,
                "total": float(total_loss.item()),
                "recon": float(recon_loss.item()),
                "phys": float(phys_loss.item()),
                "lambda_phys": float(lambda_phys),
                "K_pred_mean": float(K_pred_mean.item()),
                "Flow_pred_mean": float(Flow_pred_mean.item()),
                "Por_pred_mean": float(Por_pred_mean.item()),
                "Por_proxy_mean": float(por_proxy_mean.item()),
                "GradNorm": float(grad_norm),
            }
        )

        if epoch % 5 == 0 or epoch == 1:
            print(
                f"Epoch {epoch:3d}/{num_epochs} | "
                f"Total: {total_loss.item():.5f} | "
                f"Recon: {recon_loss.item():.5f} | "
                f"Phys: {phys_loss.item():.5f} | "
                f"Œª_phys: {lambda_phys:.2f} | "
                f"K_mean: {K_pred_mean.item():.5f} | "
                f"Flow_mean: {Flow_pred_mean.item():.5f} | "
                f"Por_solver_mean: {Por_pred_mean.item():.5f} | "
                f"Por_proxy_mean: {por_proxy_mean.item():.5f} | "
                f"GradNorm: {grad_norm:.2e}"
            )

    # Save model + logs
    os.makedirs("results/physics_informed_training", exist_ok=True)
    out_model_path = "results/model_physics_v04.pth"
    torch.save(model.state_dict(), out_model_path)
    pd.DataFrame(logs).to_csv("results/physics_training_log_v04.csv", index=False)

    print("‚úÖ Physics fine-tuning v0.4 complete.")
    print(f"üíæ Model saved ‚Üí {out_model_path}")
    print("üßæ Training log saved ‚Üí results/physics_training_log_v04.csv")


if __name__ == "__main__":
    main()


========== FILE: src/train_surrogate.py ==========

import os
import random

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset


DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
SURROGATE_DATASET_PATH = "results/surrogate_dataset.pt"
OUT_PATH = "results/physics_surrogate.pth"


class PhysicsSurrogateCNN(nn.Module):
    """
    Simple CNN regressor:
      input:  (1, 256, 256) grayscale xylem slice
      output: 5 physics metrics (Mean_K, Mean_dP/dy, FlowRate, Porosity, Anisotropy)
    """

    def __init__(self, num_outputs: int = 5):
        super().__init__()

        self.features = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),      # 16 x 128 x 128

            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),      # 32 x 64 x 64

            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),      # 64 x 32 x 32
        )

        self.head = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 32 * 32, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, num_outputs),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.features(x)
        x = self.head(x)
        return x


def load_surrogate_dataset() -> TensorDataset:
    if not os.path.exists(SURROGATE_DATASET_PATH):
        raise FileNotFoundError(
            f"{SURROGATE_DATASET_PATH} not found. "
            f"Run build_surrogate_dataset.py first."
        )

    data = torch.load(SURROGATE_DATASET_PATH, map_location="cpu")
    images = data["images"].float()          # (N, 1, H, W), in [0,1]
    metrics = data["metrics"].float()        # (N, 5)
    return TensorDataset(images, metrics)


def split_dataset(dataset: TensorDataset, val_fraction: float = 0.2):
    n = len(dataset)
    n_val = int(n * val_fraction)
    n_train = n - n_val

    indices = list(range(n))
    random.shuffle(indices)
    train_idx = indices[:n_train]
    val_idx = indices[n_train:]

    train_subset = torch.utils.data.Subset(dataset, train_idx)
    val_subset = torch.utils.data.Subset(dataset, val_idx)
    return train_subset, val_subset


def train_surrogate(
    batch_size: int = 16,
    num_epochs: int = 60,
    lr: float = 1e-3,
):
    dataset = load_surrogate_dataset()
    train_set, val_set = split_dataset(dataset, val_fraction=0.2)

    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)

    model = PhysicsSurrogateCNN(num_outputs=5).to(DEVICE)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    best_val = float("inf")

    print("üß™ Training physics surrogate on", DEVICE)
    print(f"‚úÖ Loaded surrogate dataset:")
    print("   images:", dataset.tensors[0].shape)
    print("   metrics:", dataset.tensors[1].shape)

    for epoch in range(1, num_epochs + 1):
        model.train()
        total_train = 0.0
        n_train = 0

        for xb, yb in train_loader:
            xb = xb.to(DEVICE)
            yb = yb.to(DEVICE)

            optimizer.zero_grad()
            preds = model(xb)
            loss = criterion(preds, yb)
            loss.backward()
            optimizer.step()

            total_train += loss.item() * xb.size(0)
            n_train += xb.size(0)

        loss_train = total_train / max(1, n_train)

        # validation
        model.eval()
        total_val = 0.0
        n_val = 0

        with torch.no_grad():
            for xb, yb in val_loader:
                xb = xb.to(DEVICE)
                yb = yb.to(DEVICE)
                preds = model(xb)
                loss = criterion(preds, yb)
                total_val += loss.item() * xb.size(0)
                n_val += xb.size(0)

        loss_val = total_val / max(1, n_val)

        tag = ""
        if loss_val < best_val:
            best_val = loss_val
            os.makedirs("results", exist_ok=True)
            torch.save(model.state_dict(), OUT_PATH)
            tag = "   ‚úÖ New best val loss, model saved ‚Üí results/physics_surrogate.pth"

        print(
            f"Epoch {epoch:2d}/{num_epochs:2d} | "
            f"Train MSE: {loss_train:.6f} | "
            f"Val MSE: {loss_val:.6f}{tag}"
        )

    print("üèÅ Surrogate training complete. Best val MSE:", best_val)


def main():
    train_surrogate()


if __name__ == "__main__":
    main()


========== FILE: src/train_thermal_surrogate.py ==========

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import pandas as pd
import numpy as np

# CONFIG
DATA_DIR = "data/generated_microtubes"
METRICS_FILE = "results/thermal_metrics/thermal_metrics.csv"
SAVE_PATH = "results/thermal_surrogate.pth"
BATCH_SIZE = 16
EPOCHS = 100
LR = 1e-3

# ---------------------------------------------------------
# 1. The Dataset
# ---------------------------------------------------------
class ThermalDataset(Dataset):
    def __init__(self, data_dir, csv_file, transform=None):
        self.data_dir = data_dir
        self.df = pd.read_csv(csv_file)
        self.transform = transform
        
        # We want to predict: [Q_total, rho_solid]
        # We normalize them for better training stability
        self.q_mean = self.df['Q_total'].mean()
        self.q_std = self.df['Q_total'].std()
        self.rho_mean = self.df['rho_solid'].mean()
        self.rho_std = self.df['rho_solid'].std()
        
        print(f"Dataset Stats:")
        print(f"   Q_total:   mean={self.q_mean:.4f}, std={self.q_std:.4f}")
        print(f"   rho_solid: mean={self.rho_mean:.4f}, std={self.rho_std:.4f}")

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_name = row['filename']
        img_path = os.path.join(self.data_dir, img_name)
        
        image = Image.open(img_path).convert('L')
        if self.transform:
            image = self.transform(image)
            
        # Targets
        q_val = (row['Q_total'] - self.q_mean) / (self.q_std + 1e-6)
        rho_val = (row['rho_solid'] - self.rho_mean) / (self.rho_std + 1e-6)
        
        targets = torch.tensor([q_val, rho_val], dtype=torch.float32)
        return image, targets

# ---------------------------------------------------------
# 2. The Model (Simple CNN)
# ---------------------------------------------------------
class ThermalSurrogate(nn.Module):
    def __init__(self):
        super().__init__()
        # Input: 1 channel (grayscale), 256x256
        self.features = nn.Sequential(
            nn.Conv2d(1, 16, 3, stride=2, padding=1), # 128
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, stride=2, padding=1), # 64
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, stride=2, padding=1), # 32
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, stride=2, padding=1), # 16
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((1, 1)) # Global Average Pooling -> 128 features
        )
        
        self.regressor = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 2) # Outputs: [Q_norm, Rho_norm]
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.regressor(x)
        return x

# ---------------------------------------------------------
# 3. Training Loop
# ---------------------------------------------------------
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üî• Training Thermal Surrogate on {device}...")
    
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
    ])
    
    dataset = ThermalDataset(DATA_DIR, METRICS_FILE, transform=transform)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)
    
    model = ThermalSurrogate().to(device)
    optimizer = optim.Adam(model.parameters(), lr=LR)
    criterion = nn.MSELoss()
    
    best_loss = float('inf')
    
    for epoch in range(EPOCHS):
        model.train()
        running_loss = 0.0
        
        for images, targets in dataloader:
            images, targets = images.to(device), targets.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item() * images.size(0)
            
        epoch_loss = running_loss / len(dataset)
        
        if (epoch + 1) % 10 == 0:
            print(f"   Epoch {epoch+1}/{EPOCHS} | Loss: {epoch_loss:.4f}")
            
        if epoch_loss < best_loss:
            best_loss = epoch_loss
            # Save metadata for un-normalization later
            meta = {
                'state_dict': model.state_dict(),
                'q_mean': dataset.q_mean,
                'q_std': dataset.q_std,
                'rho_mean': dataset.rho_mean,
                'rho_std': dataset.rho_std
            }
            torch.save(meta, SAVE_PATH)
            
    print(f"‚úÖ Training complete. Best Loss: {best_loss:.4f}")
    print(f"üíæ Model saved to {SAVE_PATH}")

if __name__ == "__main__":
    main()

========== FILE: synthetic_tree_physics/src/model.py ==========

"""
model.py
Defines and trains a simple convolutional autoencoder for xylem-like microstructures.
"""

import torch
import torch.nn as nn

class XylemAutoencoder(nn.Module):
    def __init__(self, latent_dim=32):
        super().__init__()
        # Encoder: compresses 256x256 image ‚Üí latent_dim
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 16, 3, stride=2, padding=1),   # 256 ‚Üí 128
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 128 ‚Üí 64
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, stride=2, padding=1),  # 64 ‚Üí 32
            nn.ReLU(),
            nn.Flatten(),
            nn.Linear(64 * 32 * 32, latent_dim)
        )

        # Decoder: reconstructs image from latent vector
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 64 * 32 * 32),
            nn.ReLU(),
            nn.Unflatten(1, (64, 32, 32)),
            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 32 ‚Üí 64
            nn.ReLU(),
            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # 64 ‚Üí 128
            nn.ReLU(),
            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),  # 128 ‚Üí 256
            nn.Sigmoid()
        )

    def forward(self, x):
        z = self.encoder(x)
        recon = self.decoder(z)
        return recon, z


