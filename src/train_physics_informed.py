"""
train_physics_informed.py  (v0.2 â€“ surrogate-based)

Fine-tune the XylemAutoencoder using a learned physics surrogate.

Pipeline:
  - Load autoencoder (results/model_hybrid.pth)
  - Load physics surrogate CNN (results/physics_surrogate.pth)
  - Load generated microtubes as training images
  - Load REAL xylem solver stats as physics targets from
    results/flow_metrics/flow_metrics.csv  (Type == "Real")
  - For each epoch:
      recon = AE(imgs)
      pred_metrics = surrogate(recon)
      physics_loss = (mean(pred_metrics) - real_targets)^2
      total_loss = recon_loss + Î» * physics_loss
  - Save tuned AE to results/model_physics_tuned.pth
  - Save full training log to results/physics_training_log.csv
"""

import os
import numpy as np
import pandas as pd
from PIL import Image

import torch
import torch.nn as nn
import torch.optim as optim

from src.model import XylemAutoencoder

DEVICE = torch.device("cpu")
TARGET_SIZE = (256, 256)

# ----------------------------------------------------
# Data loading
# ----------------------------------------------------
def load_and_preprocess_images(path):
    """Load and resize all grayscale images from a folder to consistent size."""
    imgs = []
    for f in sorted(os.listdir(path)):
        if f.lower().endswith((".png", ".jpg", ".jpeg", ".tif")):
            img = Image.open(os.path.join(path, f)).convert("L")
            img = img.resize(TARGET_SIZE, Image.BILINEAR)
            arr = np.array(img, dtype=np.float32) / 255.0
            imgs.append(torch.from_numpy(arr).unsqueeze(0))  # [1, H, W]
    if not imgs:
        raise RuntimeError(f"No images found in {path}")
    return torch.stack(imgs)  # [N, 1, H, W]


# ----------------------------------------------------
# Surrogate model (must match train_physics_surrogate.py)
# ----------------------------------------------------
class PhysicsSurrogateCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),   # 256 â†’ 128
            nn.ReLU(inplace=True),
            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 128 â†’ 64
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 64 â†’ 32
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # 32 â†’ 16
            nn.ReLU(inplace=True),
        )

        # ðŸ”§ IMPORTANT: match the architecture used during surrogate training
        self.head = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 16 * 16, 256),  # 32768 â†’ 256
            nn.ReLU(inplace=True),
            nn.Linear(256, 5),             # 256 â†’ 5
        )

    def forward(self, x):
        x = self.features(x)
        x = self.head(x)
        return x



# ----------------------------------------------------
# Load real-physics targets from flow_metrics.csv
# ----------------------------------------------------
def load_real_targets(flow_metrics_path="results/flow_metrics/flow_metrics.csv"):
    """
    Reads solver stats and returns mean targets for:
    [Mean_K, Mean_dP/dy, FlowRate, Porosity, Anisotropy] for REAL samples.
    """
    if not os.path.exists(flow_metrics_path):
        raise FileNotFoundError(
            f"Flow metrics file not found at {flow_metrics_path}. "
            "Run flow_simulation.py + flow_metrics_export first."
        )

    df = pd.read_csv(flow_metrics_path)
    if "Type" in df.columns:
        df_real = df[df["Type"].str.lower() == "real"]
    else:
        df_real = df

    cols = ["Mean_K", "Mean_dP/dy", "FlowRate", "Porosity", "Anisotropy"]
    missing = [c for c in cols if c not in df_real.columns]
    if missing:
        raise ValueError(f"Missing expected columns in flow_metrics.csv: {missing}")

    targets_np = df_real[cols].mean(axis=0).to_numpy(dtype=np.float32)
    print("ðŸŽ¯ Real-physics targets from solver:")
    for name, val in zip(cols, targets_np):
        print(f"   {name:12s} â‰ˆ {val:.6f}")

    return torch.from_numpy(targets_np).to(DEVICE), cols


# ----------------------------------------------------
# Main training loop
# ----------------------------------------------------
def main():
    print("ðŸŒ± Surrogate-based physics fine-tuning started on cpu")

    # 1) Load autoencoder
    ae = XylemAutoencoder().to(DEVICE)
    ae.load_state_dict(torch.load("results/model_hybrid.pth", map_location=DEVICE))
    ae.train()

    # 2) Load fixed surrogate
    surrogate = PhysicsSurrogateCNN().to(DEVICE)
    surrogate.load_state_dict(torch.load("results/physics_surrogate.pth", map_location=DEVICE))
    surrogate.eval()
    for p in surrogate.parameters():
        p.requires_grad = False  # freeze weights; we only backprop through AE

    # 3) Load physics targets from REAL xylem solver metrics
    target_vec, metric_names = load_real_targets("results/flow_metrics/flow_metrics.csv")

    # 4) Load training images (synthetic microtubes)
    data_path = "data/generated_microtubes"
    imgs = load_and_preprocess_images(data_path).to(DEVICE)
    print(f"ðŸ§© Loaded {imgs.shape[0]} generated structures â†’ resized to {TARGET_SIZE}")

    recon_loss_fn = nn.MSELoss()
    optimizer = optim.Adam(ae.parameters(), lr=1e-4)

    logs = []
    num_epochs = 100
    lambda_phys_start = 1.0
    lambda_phys_end = 10.0

    for epoch in range(1, num_epochs + 1):
        optimizer.zero_grad()

        recon, _ = ae(imgs)
        recon_loss = recon_loss_fn(recon, imgs)

        # Surrogate predictions on reconstructions: [B, 5]
        pred_metrics = surrogate(recon)
        pred_mean = pred_metrics.mean(dim=0)  # [5]

        # Physics loss: mean squared error vs real targets
        phys_loss = ((pred_mean - target_vec) ** 2).mean()

        # Gradually ramp physics weight
        t = epoch / num_epochs
        lambda_phys = lambda_phys_start + (lambda_phys_end - lambda_phys_start) * t

        total_loss = recon_loss + lambda_phys * phys_loss
        total_loss.backward()
        optimizer.step()

        # Gradient norm for monitoring
        grad_norm = 0.0
        for p in ae.parameters():
            if p.grad is not None:
                grad_norm += p.grad.norm().item()
        grad_norm = float(grad_norm)

        # Log
        log_row = {
            "epoch": epoch,
            "total": float(total_loss.item()),
            "recon": float(recon_loss.item()),
            "phys": float(phys_loss.item()),
            "lambda_phys": float(lambda_phys),
            "GradNorm": grad_norm,
        }
        # Also stash the current mean metrics (detached to CPU)
        for name, val in zip(metric_names, pred_mean.detach().cpu().numpy()):
            log_row[f"pred_{name}"] = float(val)

        logs.append(log_row)

        if epoch == 1 or epoch % 5 == 0:
            metrics_str = " | ".join(
                f"{name}: {log_row[f'pred_{name}']:.5f}" for name in metric_names
            )
            print(
                f"Epoch {epoch:3d}/{num_epochs} | "
                f"Total: {log_row['total']:.5f} | "
                f"Recon: {log_row['recon']:.5f} | "
                f"Phys: {log_row['phys']:.5f} | "
                f"Î»_phys: {lambda_phys:.2f} | "
                f"{metrics_str} | "
                f"GradNorm: {grad_norm:.2e}"
            )

    # 5) Save tuned model + log
    os.makedirs("results", exist_ok=True)
    torch.save(ae.state_dict(), "results/model_physics_tuned.pth")
    pd.DataFrame(logs).to_csv("results/physics_training_log.csv", index=False)

    print("âœ… Surrogate-based physics fine-tuning complete.")
    print("ðŸ’¾ Model saved â†’ results/model_physics_tuned.pth")
    print("ðŸ§¾ Training log saved â†’ results/physics_training_log.csv")


if __name__ == "__main__":
    main()
